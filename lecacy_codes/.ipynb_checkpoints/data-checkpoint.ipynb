{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d70540e-3bc7-4560-854d-3b9f8b3ca7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: s3fs in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.4.2)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from s3fs) (1.40.72)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from s3fs) (2025.10.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore>=1.12.91->s3fs) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore>=1.12.91->s3fs) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore>=1.12.91->s3fs) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.12.91->s3fs) (1.17.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install s3fs\n",
    "!pip install numpy\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77596771-ceb4-40f1-a170-ebef98e718ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "\n",
    "# s3 기본 설정\n",
    "# BUCKET = \"sagemaker-us-west-2-327784329358\"\n",
    "# S3_BASE = f\"s3://{BUCKET}\"\n",
    "\n",
    "# 입력 데이터: S3에서 바로 읽기\n",
    "# PRICE_OHLCV_PATH = f\"{S3_BASE}/prepared_data/price_ohlcv.csv\"\n",
    "# VQ_CODE_CSV_PATH = f\"{S3_BASE}/vq_vae_outputs/vq_codes_spy.csv\"\n",
    "# NEWS_CSV_PATH = f\"{S3_BASE}/prepared_data/sp500_headlines_2008_2024.csv\"\n",
    "\n",
    "# 출력 JSONL: 로컬에 만들고 S3로 업로드\n",
    "# OUTPUT_JSONL_LOCAL_PATH = \"/tmp/market_commentary_train.jsonl\"\n",
    "# OUTPUT_JSONL_S3_KEY = \"prepared_data/market_commentary_train.jsonl\"\n",
    "\n",
    "# Data Path\n",
    "OUTPUT_JSONL_LOCAL_PATH = \"prepared_data/train.jsonl\"\n",
    "SILVER_LABEL_PATH = \"silver_label_market_trend.csv\"\n",
    "PRICE_OHLCV_PATH = \"spy_2023_2024.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87970506-7ffc-417f-bd37-d99c4413dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_silver_label = pd.read_csv(SILVER_LABEL_PATH)\n",
    "df_price = pd.read_csv(PRICE_OHLCV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff64f629-697a-49f2-a9b2-ec64dbe2eee6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12327/1436947967.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPRICE_OHLCV_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrequired_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"close\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrequired_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_price\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prices_ohlcv.csv에 date, close 컬럼이 필요합니다.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# required_cols = {\"date\", \"close\"}\n",
    "# if not required_cols.issubset(df_price.columns):\n",
    "    # raise ValueError(\"prices_ohlcv.csv에 date, close 컬럼이 필요합니다.\")\n",
    "\n",
    "df_price['date'] = pd.to_datetime(df_price['date'])\n",
    "df_price['day'] = df_price['date'].dt.date\n",
    "df_price = df_price.groupby('day').tail(1)\n",
    "\n",
    "def make_summary(row):\n",
    "    return (\n",
    "        f\"open: {row['1. open']}, \"\n",
    "        f\"high: {row['2. high']}, \"\n",
    "        f\"low: {row['3. low']}, \"\n",
    "        f\"close: {row['4. close']}, \"\n",
    "        f\"volume: {row['5. volume']}\"\n",
    "    )\n",
    "\n",
    "df_price[\"ohlcv_summary\"] = df_price.apply(make_summary, axis=1)\n",
    "df_price = df_price[['day', 'ohlcv_summary']].copy()\n",
    "df_price = df_price.rename(columns={'day': 'date'})\n",
    "\n",
    "# df_price[\"date\"] = pd.to_datetime(df_price[\"date\"])\n",
    "# df_price = df_price.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# 여기서 수익률, 변동성 등 파생 피처 생성\n",
    "# df_price[\"ret_1d\"] = df_price[\"close\"].pct_change()\n",
    "# df_price[\"log_ret\"] = np.log(df_price[\"close\"]).diff()\n",
    "# df_price[\"close_ma_5\"] = df_price[\"close\"].rolling(window=5).mean()\n",
    "# df_price[\"close_ma_20\"] = df_price[\"close\"].rolling(window=20).mean()\n",
    "# df_price[\"vol_5\"] = df_price[\"log_ret\"].rolling(window=5).std()\n",
    "# df_price[\"vol_20\"] = df_price[\"log_ret\"].rolling(window=20).std()\n",
    "\n",
    "# NaN 제거\n",
    "# df_price = df_price.dropna().reset_index(drop=True)\n",
    "# print(\"[PRICE] head:\\n\", df_price.head())\n",
    "\n",
    "\n",
    "# VQ-VAE 코드와 price join\n",
    "# df_vq = pd.read_csv(VQ_CODE_CSV_PATH)\n",
    "# df_vq[\"date\"] = pd.to_datetime(df_vq[\"date\"])\n",
    "\n",
    "# df_merged = pd.merge(df_vq, df_price, on=\"date\", how=\"inner\")\n",
    "# df_merged = df_merged.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# News Headline join\n",
    "# df_news = pd.read_csv(\"NEWS_CSV_PATH\")\n",
    "# df_news[\"Date\"] = pd.to_datetime(df_news[\"Date\"])\n",
    "\n",
    "\"\"\" news_grouped = (\n",
    "    df_news.groupby(\"Date\")[\"Title\"]\n",
    "    .apply(list)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"Date\": \"date\", \"Title\": \"titles\"})\n",
    ") \"\"\"\n",
    "\n",
    "# merge all\n",
    "df_all = pd.merge(\n",
    "    df_silver_label,\n",
    "    df_price,                # VQ 코드 + 가격 요약\n",
    "    on=\"date\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2dc383-c2ea-492d-8482-96bb7516025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(code_value: int, ohlcv_summary: str):\n",
    "    prompt = (\n",
    "        \"### 코드\\n\" + str(code_value) + \"\\n\\n\"\n",
    "        \"### OHLCV 시계열\\n\" + ohlcv_summary + \"\\n\\n\"\n",
    "\n",
    "        \"위의 Code 벡터 정보와 OHLCV 시계열을 바탕으로, 해당 구간의 시장 움직임을 설명할 수 있는 한국어 뉴스 요약을 2~3 문장으로 작성하라.\"\n",
    "        \"데이터에 기반한 보수적 설명만 사용하고, 입력에 없는 사건을 새로 만들어내지 마라.\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# 프롬프트 컬럼 생성 (레이블은 placeholder)\n",
    "df_all[\"prompt\"] = df_all.apply(\n",
    "    lambda row: build_prompt(\n",
    "        code_value=row[\"code\"],\n",
    "        ohlcv_summary=row[\"ohlcv_summary\"],\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# 실제 프로젝트에서는 아래 completion을 사람/teacher LLM으로 채워넣어야 함\n",
    "# silver label을 llm api로 사용하거나 사람 손으로 gole label을 붙여 넣어야 함\n",
    "df_all[\"completion\"] = df_all[\"news_summary_raw\"]\n",
    "\n",
    "print(\"[ALL with prompt/completion] head:\\n\",\n",
    "      df_all[[\"date\", \"code\", \"prompt\", \"completion\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b8865-b1a7-4217-ae4f-b2c25f900b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def export_jsonl(df: pd.DataFrame, out_path: str) -> None:\n",
    "    os.makedirs(os.path.dirname(out_path) or \".\", exist_ok=True)\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for row in df.itertuples():\n",
    "            rec = {\n",
    "                \"prompt\": getattr(row, \"prompt\"),\n",
    "                \"completion\": getattr(row, \"completion\"),\n",
    "                \"date\": str(getattr(row, \"date\")),\n",
    "            }\n",
    "            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"Saved JSONL to {out_path}\")\n",
    "\n",
    "with \n",
    "export_jsonl(df_all, OUTPUT_JSONL_LOCAL_PATH)\n",
    "\n",
    "#upload to s3 bucket\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.upload_file(OUTPUT_JSONL_LOCAL_PATH, BUCKET, OUTPUT_JSONL_S3_KEY)\n",
    "\n",
    "print(f\"Uploaded to s3://{BUCKET}/{OUTPUT_JSONL_S3_KEY}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
