{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1fc42ed-4ea9-48ad-95fe-b8285383d459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (25.3)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.45.1)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (80.9.0)\n",
      "Collecting wandb<0.23\n",
      "  Using cached wandb-0.22.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click>=8.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from wandb<0.23) (8.3.0)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb<0.23)\n",
      "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from wandb<0.23) (24.2)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from wandb<0.23) (4.5.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from wandb<0.23) (6.31.1)\n",
      "Requirement already satisfied: pydantic<3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from wandb<0.23) (2.12.3)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from wandb<0.23) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from wandb<0.23) (2.32.5)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb<0.23)\n",
      "  Using cached sentry_sdk-2.47.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from wandb<0.23) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3->wandb<0.23) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3->wandb<0.23) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3->wandb<0.23) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb<0.23) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb<0.23) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb<0.23) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb<0.23) (2025.10.5)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb<0.23)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb<0.23)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Using cached wandb-0.22.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.0 MB)\n",
      "Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached sentry_sdk-2.47.0-py2.py3-none-any.whl (411 kB)\n",
      "Installing collected packages: smmap, sentry-sdk, gitdb, gitpython, wandb\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [wandb]32m4/5\u001b[0m [wandb]hon]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed gitdb-4.0.12 gitpython-3.1.45 sentry-sdk-2.47.0 smmap-5.0.2 wandb-0.22.3\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: google in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (3.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google) (4.14.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from beautifulsoup4->google) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from beautifulsoup4->google) (4.15.0)\n",
      "Requirement already satisfied: google-genai in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.53.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-genai) (4.11.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai) (2.43.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-genai) (2.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-genai) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-genai) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-genai) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (4.7.2)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: s3fs in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.4.2)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from s3fs) (1.40.72)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from s3fs) (2025.10.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore>=1.12.91->s3fs) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore>=1.12.91->s3fs) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore>=1.12.91->s3fs) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.12.91->s3fs) (1.17.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip wheel setuptools\n",
    "\n",
    "# Go 없이 설치 가능한 예전 버전 사용\n",
    "!pip install \"wandb<0.23\"\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install torch\n",
    "!pip install scikit-learn\n",
    "!pip install tqdm\n",
    "!pip install google\n",
    "!pip install google-genai pandas --upgrade\n",
    "!pip install s3fs\n",
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10012e2-0659-4398-a47f-8d781aa61a32",
   "metadata": {},
   "source": [
    "# VQVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69197ac-990a-4f63-bf4a-2e696f2e3da0",
   "metadata": {
    "id": "PxepWkBJBBOk"
   },
   "source": [
    "## Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e3476df-150f-46a9-b0c2-54e43ac75bb3",
   "metadata": {
    "id": "d-elOUNga6Pr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cffdb933-b95a-4d74-97ae-3d281f969cd2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBvm7KDZUNuw",
    "outputId": "71578b3a-3a6d-4f1d-e757-46b279e34d16"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8deade83-9efb-487e-8e25-33ebab55c239",
   "metadata": {
    "id": "aYA31-aCcL5N"
   },
   "outputs": [],
   "source": [
    "csv_filename = 'spy_2023_2024.csv'\n",
    "csv_filepath = '/content/drive/MyDrive/2025 ML Project/datasets/spy_data.csv'\n",
    "\n",
    "save_dir = 'prepared_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85272366-c044-4c3c-8b09-513b45560834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b0730fe-c4b0-413a-b20e-41afceded566",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qgMHLjl1UBJR",
    "outputId": "3f9ed189-4d30-47e8-86e8-caab51dd2384"
   },
   "outputs": [],
   "source": [
    "#wandb.login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb37c5c7-fc93-4c76-88ae-c9914246a557",
   "metadata": {
    "id": "my7VQ7aUkHVJ"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5922e58-37fa-4ada-b1ab-fa578694d424",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "AHoatl_lTwHg",
    "outputId": "8cb880f5-b169-401f-fa14-d3986b7dcc1c"
   },
   "outputs": [],
   "source": [
    "# csv to DF\n",
    "data = pd.read_csv(csv_filename)\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "555cc950-637d-4667-8016-b5fd66c51944",
   "metadata": {
    "id": "9YuOEHEEXGsq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-03 09:30:00</td>\n",
       "      <td>370.5398</td>\n",
       "      <td>372.5257</td>\n",
       "      <td>367.9274</td>\n",
       "      <td>367.9755</td>\n",
       "      <td>7391068.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-03 10:00:00</td>\n",
       "      <td>368.0334</td>\n",
       "      <td>368.8142</td>\n",
       "      <td>366.4669</td>\n",
       "      <td>367.2332</td>\n",
       "      <td>4314212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-03 10:30:00</td>\n",
       "      <td>367.1850</td>\n",
       "      <td>368.3467</td>\n",
       "      <td>366.3946</td>\n",
       "      <td>368.2937</td>\n",
       "      <td>3567632.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-03 11:00:00</td>\n",
       "      <td>368.3032</td>\n",
       "      <td>368.5732</td>\n",
       "      <td>365.8258</td>\n",
       "      <td>366.3639</td>\n",
       "      <td>4035712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-03 11:30:00</td>\n",
       "      <td>366.3656</td>\n",
       "      <td>366.3753</td>\n",
       "      <td>365.0256</td>\n",
       "      <td>365.4305</td>\n",
       "      <td>3691236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6521</th>\n",
       "      <td>6521</td>\n",
       "      <td>2024-12-31 13:30:00</td>\n",
       "      <td>579.9381</td>\n",
       "      <td>581.4202</td>\n",
       "      <td>579.8440</td>\n",
       "      <td>580.2603</td>\n",
       "      <td>1760552.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6522</th>\n",
       "      <td>6522</td>\n",
       "      <td>2024-12-31 14:00:00</td>\n",
       "      <td>580.2801</td>\n",
       "      <td>581.4696</td>\n",
       "      <td>579.5069</td>\n",
       "      <td>579.8638</td>\n",
       "      <td>3210970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6523</th>\n",
       "      <td>6523</td>\n",
       "      <td>2024-12-31 14:30:00</td>\n",
       "      <td>579.8440</td>\n",
       "      <td>581.2516</td>\n",
       "      <td>579.3483</td>\n",
       "      <td>581.2417</td>\n",
       "      <td>3129664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>6524</td>\n",
       "      <td>2024-12-31 15:00:00</td>\n",
       "      <td>581.2219</td>\n",
       "      <td>582.2033</td>\n",
       "      <td>580.0918</td>\n",
       "      <td>582.1340</td>\n",
       "      <td>3598139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6525</th>\n",
       "      <td>6525</td>\n",
       "      <td>2024-12-31 15:30:00</td>\n",
       "      <td>582.1339</td>\n",
       "      <td>582.4015</td>\n",
       "      <td>579.8935</td>\n",
       "      <td>580.9245</td>\n",
       "      <td>12574003.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6526 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                date   1. open   2. high    3. low  4. close  \\\n",
       "0              0 2023-01-03 09:30:00  370.5398  372.5257  367.9274  367.9755   \n",
       "1              1 2023-01-03 10:00:00  368.0334  368.8142  366.4669  367.2332   \n",
       "2              2 2023-01-03 10:30:00  367.1850  368.3467  366.3946  368.2937   \n",
       "3              3 2023-01-03 11:00:00  368.3032  368.5732  365.8258  366.3639   \n",
       "4              4 2023-01-03 11:30:00  366.3656  366.3753  365.0256  365.4305   \n",
       "...          ...                 ...       ...       ...       ...       ...   \n",
       "6521        6521 2024-12-31 13:30:00  579.9381  581.4202  579.8440  580.2603   \n",
       "6522        6522 2024-12-31 14:00:00  580.2801  581.4696  579.5069  579.8638   \n",
       "6523        6523 2024-12-31 14:30:00  579.8440  581.2516  579.3483  581.2417   \n",
       "6524        6524 2024-12-31 15:00:00  581.2219  582.2033  580.0918  582.1340   \n",
       "6525        6525 2024-12-31 15:30:00  582.1339  582.4015  579.8935  580.9245   \n",
       "\n",
       "       5. volume  \n",
       "0      7391068.0  \n",
       "1      4314212.0  \n",
       "2      3567632.0  \n",
       "3      4035712.0  \n",
       "4      3691236.0  \n",
       "...          ...  \n",
       "6521   1760552.0  \n",
       "6522   3210970.0  \n",
       "6523   3129664.0  \n",
       "6524   3598139.0  \n",
       "6525  12574003.0  \n",
       "\n",
       "[6526 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eb981ac-4d9e-4a52-a8cc-47bfefaf04d8",
   "metadata": {
    "id": "-lZnIKWWmLVg"
   },
   "outputs": [],
   "source": [
    "## 하루를 기준으로 정규화\n",
    "def normalize_per_day(group):\n",
    "  ohlc = ['1. open', '2. high', '3. low', '4. close']\n",
    "\n",
    "  min_val = group[ohlc].min().min()\n",
    "  max_val = group[ohlc].max().max()\n",
    "\n",
    "  if max_val - min_val > 0:\n",
    "    group[ohlc] = (group[ohlc] - min_val) / (max_val - min_val)\n",
    "  else:\n",
    "    group[ohlc] = 0.5\n",
    "\n",
    "  ## 일단 volume도 하루 단위로 정규화\n",
    "  min_vol = group['5. volume'].min()\n",
    "  max_vol = group['5. volume'].max()\n",
    "  group['5. volume'] = (group['5. volume'] - min_vol) / (max_vol - min_vol)\n",
    "\n",
    "  return group\n",
    "\n",
    "normalized_data = data.groupby(data['date'].dt.date).apply(normalize_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d55fc900-9bde-4f18-978d-13844927a768",
   "metadata": {
    "id": "sG5N1W0YbO07"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2023-01-03</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-03 09:30:00</td>\n",
       "      <td>0.760435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.445293</td>\n",
       "      <td>0.451095</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-03 10:00:00</td>\n",
       "      <td>0.458080</td>\n",
       "      <td>0.552270</td>\n",
       "      <td>0.269108</td>\n",
       "      <td>0.361549</td>\n",
       "      <td>0.438819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-03 10:30:00</td>\n",
       "      <td>0.355735</td>\n",
       "      <td>0.495874</td>\n",
       "      <td>0.260387</td>\n",
       "      <td>0.489481</td>\n",
       "      <td>0.302651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-03 11:00:00</td>\n",
       "      <td>0.490627</td>\n",
       "      <td>0.523198</td>\n",
       "      <td>0.191770</td>\n",
       "      <td>0.256683</td>\n",
       "      <td>0.388024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-03 11:30:00</td>\n",
       "      <td>0.256888</td>\n",
       "      <td>0.258058</td>\n",
       "      <td>0.095240</td>\n",
       "      <td>0.144084</td>\n",
       "      <td>0.325195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2024-12-31</th>\n",
       "      <th>6521</th>\n",
       "      <td>6521</td>\n",
       "      <td>2024-12-31 13:30:00</td>\n",
       "      <td>0.095655</td>\n",
       "      <td>0.336026</td>\n",
       "      <td>0.080394</td>\n",
       "      <td>0.147910</td>\n",
       "      <td>0.012937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6522</th>\n",
       "      <td>6522</td>\n",
       "      <td>2024-12-31 14:00:00</td>\n",
       "      <td>0.151121</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.025722</td>\n",
       "      <td>0.083605</td>\n",
       "      <td>0.145332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6523</th>\n",
       "      <td>6523</td>\n",
       "      <td>2024-12-31 14:30:00</td>\n",
       "      <td>0.080394</td>\n",
       "      <td>0.308682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307076</td>\n",
       "      <td>0.137911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>6524</td>\n",
       "      <td>2024-12-31 15:00:00</td>\n",
       "      <td>0.303865</td>\n",
       "      <td>0.463031</td>\n",
       "      <td>0.120583</td>\n",
       "      <td>0.451791</td>\n",
       "      <td>0.180674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6525</th>\n",
       "      <td>6525</td>\n",
       "      <td>2024-12-31 15:30:00</td>\n",
       "      <td>0.451775</td>\n",
       "      <td>0.495175</td>\n",
       "      <td>0.088422</td>\n",
       "      <td>0.255632</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6526 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Unnamed: 0                date   1. open   2. high    3. low  \\\n",
       "date                                                                            \n",
       "2023-01-03 0              0 2023-01-03 09:30:00  0.760435  1.000000  0.445293   \n",
       "           1              1 2023-01-03 10:00:00  0.458080  0.552270  0.269108   \n",
       "           2              2 2023-01-03 10:30:00  0.355735  0.495874  0.260387   \n",
       "           3              3 2023-01-03 11:00:00  0.490627  0.523198  0.191770   \n",
       "           4              4 2023-01-03 11:30:00  0.256888  0.258058  0.095240   \n",
       "...                     ...                 ...       ...       ...       ...   \n",
       "2024-12-31 6521        6521 2024-12-31 13:30:00  0.095655  0.336026  0.080394   \n",
       "           6522        6522 2024-12-31 14:00:00  0.151121  0.344037  0.025722   \n",
       "           6523        6523 2024-12-31 14:30:00  0.080394  0.308682  0.000000   \n",
       "           6524        6524 2024-12-31 15:00:00  0.303865  0.463031  0.120583   \n",
       "           6525        6525 2024-12-31 15:30:00  0.451775  0.495175  0.088422   \n",
       "\n",
       "                 4. close  5. volume  \n",
       "date                                  \n",
       "2023-01-03 0     0.451095   1.000000  \n",
       "           1     0.361549   0.438819  \n",
       "           2     0.489481   0.302651  \n",
       "           3     0.256683   0.388024  \n",
       "           4     0.144084   0.325195  \n",
       "...                   ...        ...  \n",
       "2024-12-31 6521  0.147910   0.012937  \n",
       "           6522  0.083605   0.145332  \n",
       "           6523  0.307076   0.137911  \n",
       "           6524  0.451791   0.180674  \n",
       "           6525  0.255632   1.000000  \n",
       "\n",
       "[6526 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa6e7251-6fbf-4ea1-84b6-c513d1ecf3cf",
   "metadata": {
    "id": "bZW-xMP9di10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">2023-01-03</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-03 09:30:00</td>\n",
       "      <td>0.760435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.445293</td>\n",
       "      <td>0.451095</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-03 10:00:00</td>\n",
       "      <td>0.458080</td>\n",
       "      <td>0.552270</td>\n",
       "      <td>0.269108</td>\n",
       "      <td>0.361549</td>\n",
       "      <td>0.438819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-03 10:30:00</td>\n",
       "      <td>0.355735</td>\n",
       "      <td>0.495874</td>\n",
       "      <td>0.260387</td>\n",
       "      <td>0.489481</td>\n",
       "      <td>0.302651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-03 11:00:00</td>\n",
       "      <td>0.490627</td>\n",
       "      <td>0.523198</td>\n",
       "      <td>0.191770</td>\n",
       "      <td>0.256683</td>\n",
       "      <td>0.388024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-03 11:30:00</td>\n",
       "      <td>0.256888</td>\n",
       "      <td>0.258058</td>\n",
       "      <td>0.095240</td>\n",
       "      <td>0.144084</td>\n",
       "      <td>0.325195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-01-03 12:00:00</td>\n",
       "      <td>0.148741</td>\n",
       "      <td>0.220843</td>\n",
       "      <td>0.069666</td>\n",
       "      <td>0.128969</td>\n",
       "      <td>0.096589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2023-01-03 12:30:00</td>\n",
       "      <td>0.131876</td>\n",
       "      <td>0.254572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090595</td>\n",
       "      <td>0.131098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-03 13:00:00</td>\n",
       "      <td>0.092924</td>\n",
       "      <td>0.215692</td>\n",
       "      <td>0.059195</td>\n",
       "      <td>0.196415</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2023-01-03 13:30:00</td>\n",
       "      <td>0.196415</td>\n",
       "      <td>0.251074</td>\n",
       "      <td>0.131297</td>\n",
       "      <td>0.232472</td>\n",
       "      <td>0.008069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2023-01-03 14:00:00</td>\n",
       "      <td>0.233630</td>\n",
       "      <td>0.278988</td>\n",
       "      <td>0.111525</td>\n",
       "      <td>0.134783</td>\n",
       "      <td>0.086460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2023-01-03 14:30:00</td>\n",
       "      <td>0.135953</td>\n",
       "      <td>0.339461</td>\n",
       "      <td>0.030122</td>\n",
       "      <td>0.256876</td>\n",
       "      <td>0.366619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2023-01-03 15:00:00</td>\n",
       "      <td>0.254572</td>\n",
       "      <td>0.385978</td>\n",
       "      <td>0.231302</td>\n",
       "      <td>0.294103</td>\n",
       "      <td>0.294148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2023-01-03 15:30:00</td>\n",
       "      <td>0.295274</td>\n",
       "      <td>0.403421</td>\n",
       "      <td>0.285961</td>\n",
       "      <td>0.349920</td>\n",
       "      <td>0.981363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2023-01-04 09:30:00</td>\n",
       "      <td>0.540805</td>\n",
       "      <td>0.709177</td>\n",
       "      <td>0.323125</td>\n",
       "      <td>0.549326</td>\n",
       "      <td>0.480972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Unnamed: 0                date   1. open   2. high    3. low  \\\n",
       "date                                                                          \n",
       "2023-01-03 0            0 2023-01-03 09:30:00  0.760435  1.000000  0.445293   \n",
       "           1            1 2023-01-03 10:00:00  0.458080  0.552270  0.269108   \n",
       "           2            2 2023-01-03 10:30:00  0.355735  0.495874  0.260387   \n",
       "           3            3 2023-01-03 11:00:00  0.490627  0.523198  0.191770   \n",
       "           4            4 2023-01-03 11:30:00  0.256888  0.258058  0.095240   \n",
       "           5            5 2023-01-03 12:00:00  0.148741  0.220843  0.069666   \n",
       "           6            6 2023-01-03 12:30:00  0.131876  0.254572  0.000000   \n",
       "           7            7 2023-01-03 13:00:00  0.092924  0.215692  0.059195   \n",
       "           8            8 2023-01-03 13:30:00  0.196415  0.251074  0.131297   \n",
       "           9            9 2023-01-03 14:00:00  0.233630  0.278988  0.111525   \n",
       "           10          10 2023-01-03 14:30:00  0.135953  0.339461  0.030122   \n",
       "           11          11 2023-01-03 15:00:00  0.254572  0.385978  0.231302   \n",
       "           12          12 2023-01-03 15:30:00  0.295274  0.403421  0.285961   \n",
       "2023-01-04 13          13 2023-01-04 09:30:00  0.540805  0.709177  0.323125   \n",
       "\n",
       "               4. close  5. volume  \n",
       "date                                \n",
       "2023-01-03 0   0.451095   1.000000  \n",
       "           1   0.361549   0.438819  \n",
       "           2   0.489481   0.302651  \n",
       "           3   0.256683   0.388024  \n",
       "           4   0.144084   0.325195  \n",
       "           5   0.128969   0.096589  \n",
       "           6   0.090595   0.131098  \n",
       "           7   0.196415   0.000000  \n",
       "           8   0.232472   0.008069  \n",
       "           9   0.134783   0.086460  \n",
       "           10  0.256876   0.366619  \n",
       "           11  0.294103   0.294148  \n",
       "           12  0.349920   0.981363  \n",
       "2023-01-04 13  0.549326   0.480972  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4645f2f3-1be6-4042-9efd-e230b143ed69",
   "metadata": {
    "id": "P9hC1FEPQOBw"
   },
   "outputs": [],
   "source": [
    "class SPYDataSet(Dataset):\n",
    "  def __init__(self, data, features, chunk_size):\n",
    "    self.chunk_size = chunk_size\n",
    "\n",
    "    arr = data[features].to_numpy(dtype=np.float32)\n",
    "    self.arr = arr\n",
    "    self.N, self.C = arr.shape\n",
    "\n",
    "    self.num_chunks = self.N // self.chunk_size\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.num_chunks\n",
    "\n",
    "  def __getitem__(self, idx: int):\n",
    "    start = idx * self.chunk_size\n",
    "    end = start + self.chunk_size\n",
    "\n",
    "    x = self.arr[start:end]\n",
    "    x = torch.from_numpy(x).float().T\n",
    "    return {\"x\": x, \"idx\": idx}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a3de2f1-0dec-40fa-b04e-9fe96165eb39",
   "metadata": {},
   "source": [
    "print(normalized_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab9d0ca6-3e16-4719-b7ae-e9d94cc7129d",
   "metadata": {
    "id": "GFgmca1bTvMG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502\n"
     ]
    }
   ],
   "source": [
    "feature_cols = ['1. open', '2. high', '3. low', '4. close', '5. volume']\n",
    "\n",
    "ds = SPYDataSet(normalized_data, features=feature_cols, chunk_size=13)\n",
    "print(len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed32b7f6-8a49-4d96-be99-d70100b65e15",
   "metadata": {
    "id": "52ns6Z72eGu6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[0.7604, 0.4581, 0.3557, 0.4906, 0.2569, 0.1487, 0.1319, 0.0929, 0.1964,\n",
       "          0.2336, 0.1360, 0.2546, 0.2953],\n",
       "         [1.0000, 0.5523, 0.4959, 0.5232, 0.2581, 0.2208, 0.2546, 0.2157, 0.2511,\n",
       "          0.2790, 0.3395, 0.3860, 0.4034],\n",
       "         [0.4453, 0.2691, 0.2604, 0.1918, 0.0952, 0.0697, 0.0000, 0.0592, 0.1313,\n",
       "          0.1115, 0.0301, 0.2313, 0.2860],\n",
       "         [0.4511, 0.3615, 0.4895, 0.2567, 0.1441, 0.1290, 0.0906, 0.1964, 0.2325,\n",
       "          0.1348, 0.2569, 0.2941, 0.3499],\n",
       "         [1.0000, 0.4388, 0.3027, 0.3880, 0.3252, 0.0966, 0.1311, 0.0000, 0.0081,\n",
       "          0.0865, 0.3666, 0.2941, 0.9814]]),\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0] # C(5) * T(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9249b569-56f4-402f-80ba-a8d154a62318",
   "metadata": {
    "id": "4cjvy5HNbArz"
   },
   "source": [
    "## VQ-VAE Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00a8ba11-650e-4429-acbe-eb0c37d63cb8",
   "metadata": {
    "id": "ZhK2KfrE0a0Q"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "    super().__init__()\n",
    "    self.conv = nn.Sequential(\n",
    "        nn.Conv1d(input_dim, hidden_dim, kernel_size=5, stride=2, padding=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, stride=1, padding=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv1d(hidden_dim, latent_dim, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.AdaptiveAvgPool1d(1)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "201bf136-a0f6-421e-96d1-2d3143ae4f8e",
   "metadata": {
    "id": "_VxbOuDNbAHm"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.deconv = nn.Sequential(\n",
    "          nn.ConvTranspose1d(latent_dim, hidden_dim, kernel_size=7, stride=1, padding=0),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "          nn.ConvTranspose1d(hidden_dim, hidden_dim, kernel_size=3, stride=2, padding=1, output_padding=0),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv1d(hidden_dim, output_dim, kernel_size=3, stride=1, padding=1)\n",
    "      )\n",
    "\n",
    "  def forward(self, z_q):\n",
    "      return self.deconv(z_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f74e12cf-b423-44de-ae44-51e03204be28",
   "metadata": {
    "id": "JIMne24hAoV6"
   },
   "outputs": [],
   "source": [
    "class VectorQuantizer(nn.Module):\n",
    "  \"\"\" num_embeddings: K (codebook size)\n",
    "      embedding_dim:  D (code dimension)\n",
    "      commitment_cost: beta in the paper \"\"\"\n",
    "\n",
    "  def __init__(self, num_embeddings, embedding_dim, commitment_cost):\n",
    "    super().__init__()\n",
    "    self.num_embeddings = num_embeddings\n",
    "    self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    self.commitment_cost = commitment_cost\n",
    "    self.embedding.weight.data.uniform_(-1/num_embeddings, 1/num_embeddings)\n",
    "\n",
    "  def forward(self, z):\n",
    "    B, D, T = z.shape\n",
    "    z_perm = z.permute(0, 2, 1).contiguous()\n",
    "    z_flattened = z_perm.view(-1, D)\n",
    "\n",
    "    e = self.embedding.weight\n",
    "    z_sq = (z_flattened ** 2).sum(dim=1, keepdim=True)\n",
    "    e_sq = (e ** 2).sum(dim=1)\n",
    "    ze = z_flattened @ e.t()\n",
    "    distances = z_sq + e_sq.unsqueeze(0) - 2 * ze\n",
    "\n",
    "    encoding_indices = torch.argmin(distances, dim=1)\n",
    "    z_q = self.embedding(encoding_indices).view(B, T, D).permute(0, 2, 1).contiguous()\n",
    "\n",
    "    codebook_loss =  F.mse_loss(z_q, z.detach())\n",
    "    commitment_loss = self.commitment_cost * F.mse_loss(z_q.detach(), z)\n",
    "    vq_loss = codebook_loss + 0.5 * commitment_loss\n",
    "\n",
    "    z_q = z + (z_q - z).detach()\n",
    "\n",
    "    indices_bt = encoding_indices.view(B, T)\n",
    "    return z_q, vq_loss, indices_bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc7d4571-3618-40e7-9766-1fc23f7cebf7",
   "metadata": {
    "id": "fdAPcd73Fj7w"
   },
   "outputs": [],
   "source": [
    "class VQVAE(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, latent_dim, num_embeddings, commitment_cost):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(input_dim, hidden_dim, latent_dim)\n",
    "    self.vq = VectorQuantizer(num_embeddings, latent_dim, commitment_cost)\n",
    "    self.decoder = Decoder(latent_dim, hidden_dim, input_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    z_e = self.encoder(x)\n",
    "    z_q, vq_loss, indices = self.vq(z_e)\n",
    "    x_recon = self.decoder(z_q)\n",
    "    return x_recon, vq_loss, indices, z_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb2f7dfe-a6c9-47cd-b82b-57d30ee377b7",
   "metadata": {
    "id": "Rh3jGTuZsKfN"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "  index_list = []\n",
    "  sum_recon, sum_vq = 0.0, 0.0\n",
    "  n = 0\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for batch in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "      X = batch[\"x\"].to(device)\n",
    "\n",
    "      x_recon, vq_loss, indices, _ = model(X)\n",
    "\n",
    "      recon_loss = F.mse_loss(x_recon, X)\n",
    "\n",
    "      batch_size = X.size(0)\n",
    "      sum_recon += recon_loss.item() * batch_size\n",
    "      sum_vq += vq_loss.item() * batch_size\n",
    "      n += batch_size\n",
    "\n",
    "      index_list.append(indices)\n",
    "\n",
    "    mean_recon = sum_recon / max(n, 1)\n",
    "    mean_vq = sum_vq / max(n, 1)\n",
    "    sum_loss = mean_recon + mean_vq\n",
    "\n",
    "    return mean_recon, mean_vq, sum_loss, index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a405f792-e24b-4269-8617-5e8399dcab56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/wandb/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "print(wandb.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f098fdd-2364-4ba3-83d8-9366b0ebf688",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs= [{\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 3e-4,\n",
    "        \"epochs\": 200,\n",
    "        \"num_embeddings\": 16,\n",
    "        \"commitment_cost\":0.25\n",
    "    }, {\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 3e-4,\n",
    "        \"epochs\": 200,\n",
    "        \"num_embeddings\": 16,\n",
    "        \"commitment_cost\":0.4\n",
    "    }, {\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 3e-4,\n",
    "        \"epochs\": 200,\n",
    "        \"num_embeddings\": 32,\n",
    "        \"commitment_cost\":0.25\n",
    "    }, {\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 3e-4,\n",
    "        \"epochs\": 200,\n",
    "        \"num_embeddings\": 32,\n",
    "        \"commitment_cost\":0.4\n",
    "    }, {\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 3e-4,\n",
    "        \"epochs\": 200,\n",
    "        \"num_embeddings\": 64,\n",
    "        \"commitment_cost\":0.25\n",
    "    }, {\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 3e-4,\n",
    "        \"epochs\": 200,\n",
    "        \"num_embeddings\": 64,\n",
    "        \"commitment_cost\":0.4\n",
    "    }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3a06455-8c12-4c49-bfd4-06932e1d1c42",
   "metadata": {
    "id": "AarAtJwBUhoD"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched '[' (3526537479.py, line 85)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_29962/3526537479.py\"\u001b[0;36m, line \u001b[0;32m85\u001b[0m\n\u001b[0;31m    best_model_path = os.path.join(\"model/vqvae/\", f\"num_embedding_{cfg[\"num_embeddings\"]}_commitment_cost_{cfg[\"commitment_cost\"]}.pt\")\u001b[0m\n\u001b[0m                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: unmatched '['\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(configs)):\n",
    "    cfg = configs[i]\n",
    "    wandb.init(\n",
    "        project=\"2025 ML Project\",\n",
    "        mode=\"offline\",\n",
    "        entity=\"youani-korea-university\",\n",
    "        name=\"1 vector_8\",\n",
    "        config= cfg\n",
    "    )\n",
    "    \n",
    "    N = len(ds)\n",
    "    train_len = int(N * 0.7)\n",
    "    val_len = int(N * 0.15)\n",
    "    test_len = N - train_len - val_len\n",
    "    \n",
    "    ds_train, ds_val, ds_test = random_split(ds, [train_len, val_len, test_len])\n",
    "    train_loader = DataLoader(ds_train, batch_size=wandb.config.batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader   = DataLoader(ds_val, batch_size=wandb.config.batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(ds_test, batch_size=wandb.config.batch_size, shuffle=False)\n",
    "    \n",
    "    # parameter setting\n",
    "    input_dim = 5\n",
    "    hidden_dim = 64\n",
    "    latent_dim = 8\n",
    "    num_embeddings = wandb.config.num_embeddings\n",
    "    commitment_cost = wandb.config.commitment_cost\n",
    "    \n",
    "    # model training\n",
    "    lr = wandb.config.learning_rate\n",
    "    epochs = wandb.config.epochs\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = VQVAE(input_dim, hidden_dim, latent_dim, num_embeddings, commitment_cost)\n",
    "    model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    recon_hist, vq_hist = [], []\n",
    "    \n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_path = 'prepared_data/best_model_epoch.pt'\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "      model.train()\n",
    "      sum_recon, sum_vq = 0.0, 0.0\n",
    "      n = 0\n",
    "    \n",
    "      for batch in tqdm(train_loader, desc=\"Train\", leave=False):\n",
    "        X = batch['x'].to(device)\n",
    "        opt.zero_grad()\n",
    "        x_recon, vq_loss, indices, _ = model(X)\n",
    "    \n",
    "        if x_recon.size(-1) != X.size(-1):\n",
    "          print(\"Error: reconstruction size not equal to original\")\n",
    "          x_recon = F.interpolate(x_recon, size=X.size(-1), mode='linear', align_corners=False)\n",
    "    \n",
    "        recon_loss = F.mse_loss(x_recon, X)\n",
    "        loss = recon_loss + vq_loss\n",
    "    \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "        batch_size = X.size(0)\n",
    "        sum_recon += recon_loss.item() * batch_size\n",
    "        sum_vq += vq_loss.item() * batch_size\n",
    "        n += batch_size\n",
    "    \n",
    "      epoch_recon = sum_recon / max(n, 1)\n",
    "      epoch_vq = sum_vq / max(n, 1)\n",
    "    \n",
    "      recon_hist.append(epoch_recon)\n",
    "      vq_hist.append(epoch_vq)\n",
    "    \n",
    "      tqdm.write(f\"[{epoch:03d}/{epochs:03d} Training] recon={epoch_recon:.6f} vq={epoch_vq:.6f}\")\n",
    "    \n",
    "      val_recon, val_vq, val_loss, index_list = evaluate(model, val_loader, device)\n",
    "      index_total = torch.cat(index_list).view(-1)\n",
    "      usage_rate = len(index_total.unique()) / model.vq.num_embeddings\n",
    "      wandb.log({\n",
    "          f'valid_epoch_recon': val_recon,\n",
    "          f'valid_epoch_vq': val_vq,\n",
    "          f'usage_rate': usage_rate\n",
    "      })\n",
    "      tqdm.write(f\"[{epoch:03d}/{epochs:03d} Validation] recon={val_recon:.6f} vq={val_vq:.6f}\")\n",
    "    \n",
    "      if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_path = os.path.join(\"model/vqvae/\",f\"num_embedding_{cfg['num_embeddings']}_commitment_cost_{cfg['commitment_cost']}.pt\")\n",
    "        torch.save(model.state_dict(),best_model_path)\n",
    "    \n",
    "    print(f\"Training Finished. Best model: {best_model_path} (val_loss: {best_val_loss:.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "205292df-fa4a-4036-b5cd-84c3995bd932",
   "metadata": {
    "id": "wBN2WgyU5qCw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] recon=0.070696 vq=0.001685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "test_recon, test_vq, test_loss, index_list = evaluate(model, test_loader, device)\n",
    "wandb.log({\n",
    "    f'test_epoch_recon': test_recon,\n",
    "    f'test_epoch_vq': test_vq\n",
    "})\n",
    "print(f\"[Test] recon={test_recon:.6f} vq={test_vq:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ebacdc8-97e7-4ee2-8f8a-07cbe7ef7c08",
   "metadata": {
    "id": "lVtcCCnRJPd8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_epoch_recon</td><td>▁▁</td></tr><tr><td>test_epoch_vq</td><td>▁▁</td></tr><tr><td>usage_rate</td><td>▂▂▁▁▁▂▅▅▇▇███▄▄▄▄▄▄▄▄▄▅▄▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇</td></tr><tr><td>valid_epoch_recon</td><td>█▆▆▆▅▄▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_epoch_vq</td><td>▁▁▁▁▁▂▂▃▂▂▄▅▆▇▇▇█▇▇██▇▇▇▇▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_epoch_recon</td><td>0.0707</td></tr><tr><td>test_epoch_vq</td><td>0.00168</td></tr><tr><td>usage_rate</td><td>0.15625</td></tr><tr><td>valid_epoch_recon</td><td>0.03325</td></tr><tr><td>valid_epoch_vq</td><td>0.1729</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br><code>wandb sync /home/ec2-user/SageMaker/wandb/offline-run-20251207_131544-yos0xejo<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20251207_131544-yos0xejo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed6349-be65-43a2-a1bb-612588629a63",
   "metadata": {
    "id": "-OvkT-EyglYV"
   },
   "source": [
    "## Get Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e6c922e-ddc1-4ce4-bf81-a4889e113f95",
   "metadata": {
    "id": "GzGIBH2BSjdv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [10],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [29],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [19],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23],\n",
       "        [23]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_x = []\n",
    "all_assign = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in test_loader:\n",
    "    X = batch[\"x\"].to(device)\n",
    "    _, _, indices, _ = model(X)\n",
    "\n",
    "    all_x.append(X.cpu())\n",
    "    all_assign.append(indices.cpu())\n",
    "\n",
    "X = torch.cat(all_x, dim=0)\n",
    "assign = torch.cat(all_assign, dim=0)\n",
    "assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2dd4dbad-3764-4280-ac16-f215594ed38c",
   "metadata": {
    "id": "umtq38g_oETh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([0, 5, 13])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (assign == 16).squeeze(1)\n",
    "sample = X[mask]\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e351b3f5-2846-43b4-ba86-42421f69a95c",
   "metadata": {
    "id": "RCE9z-U46RB_"
   },
   "outputs": [],
   "source": [
    "selected = mask.nonzero(as_tuple=True)[0]\n",
    "origin_indices = [int(test_loader.dataset[i.item()][\"idx\"]) for i in selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6243143e-2c93-46d3-9306-d030cb7e0606",
   "metadata": {
    "id": "hFkVPciW_tni"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(origin_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3821b1c8-ade2-4fef-b3f6-e51e973b3ce5",
   "metadata": {
    "id": "-_4pfJ_HCFv9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data selected for the given indices.\n"
     ]
    }
   ],
   "source": [
    "selected_data = []\n",
    "for idx in origin_indices:\n",
    "    selected_rows = normalized_data.loc[(normalized_data.index.get_level_values(1) >= idx * 13) & (normalized_data.index.get_level_values(1) < idx * 13 + 13)]\n",
    "    selected_data.append(selected_rows)\n",
    "\n",
    "if selected_data:\n",
    "    result_df = pd.concat(selected_data)\n",
    "    result_df = result_df.reset_index(drop=True).sort_values(by='date', ascending=True)\n",
    "    display(result_df)\n",
    "else:\n",
    "    print(\"No data selected for the given indices.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ab7717b-5627-4e06-a8ea-799960b7783a",
   "metadata": {
    "id": "aPd-UJnNa0Xf",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>2023-01-13 09:30:00</td>\n",
       "      <td>379.4570</td>\n",
       "      <td>380.9994</td>\n",
       "      <td>379.1871</td>\n",
       "      <td>380.5271</td>\n",
       "      <td>5376205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>2023-01-13 10:00:00</td>\n",
       "      <td>380.5463</td>\n",
       "      <td>382.2912</td>\n",
       "      <td>380.1415</td>\n",
       "      <td>382.2237</td>\n",
       "      <td>5289551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>2023-01-13 10:30:00</td>\n",
       "      <td>382.2334</td>\n",
       "      <td>382.4840</td>\n",
       "      <td>381.6164</td>\n",
       "      <td>382.1177</td>\n",
       "      <td>3208173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>2023-01-13 11:00:00</td>\n",
       "      <td>382.1176</td>\n",
       "      <td>382.3105</td>\n",
       "      <td>381.1440</td>\n",
       "      <td>381.7417</td>\n",
       "      <td>2821641.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>2023-01-13 11:30:00</td>\n",
       "      <td>381.7610</td>\n",
       "      <td>381.8092</td>\n",
       "      <td>381.0091</td>\n",
       "      <td>381.5586</td>\n",
       "      <td>2337478.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>109</td>\n",
       "      <td>2023-01-13 12:00:00</td>\n",
       "      <td>381.5682</td>\n",
       "      <td>382.3201</td>\n",
       "      <td>381.4766</td>\n",
       "      <td>382.2141</td>\n",
       "      <td>1774791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>110</td>\n",
       "      <td>2023-01-13 12:30:00</td>\n",
       "      <td>382.2141</td>\n",
       "      <td>382.5563</td>\n",
       "      <td>381.7706</td>\n",
       "      <td>382.4262</td>\n",
       "      <td>1741349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>111</td>\n",
       "      <td>2023-01-13 13:00:00</td>\n",
       "      <td>382.4214</td>\n",
       "      <td>382.6383</td>\n",
       "      <td>381.8382</td>\n",
       "      <td>382.1851</td>\n",
       "      <td>1930195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>2023-01-13 13:30:00</td>\n",
       "      <td>382.1852</td>\n",
       "      <td>383.3613</td>\n",
       "      <td>382.0695</td>\n",
       "      <td>383.2167</td>\n",
       "      <td>2834272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>113</td>\n",
       "      <td>2023-01-13 14:00:00</td>\n",
       "      <td>383.2094</td>\n",
       "      <td>383.4577</td>\n",
       "      <td>382.8696</td>\n",
       "      <td>383.2745</td>\n",
       "      <td>2496351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>2023-01-13 14:30:00</td>\n",
       "      <td>383.2842</td>\n",
       "      <td>383.5252</td>\n",
       "      <td>383.0142</td>\n",
       "      <td>383.3324</td>\n",
       "      <td>2667838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>2023-01-13 15:00:00</td>\n",
       "      <td>383.3516</td>\n",
       "      <td>383.9686</td>\n",
       "      <td>383.2938</td>\n",
       "      <td>383.9499</td>\n",
       "      <td>3092575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>2023-01-13 15:30:00</td>\n",
       "      <td>383.9686</td>\n",
       "      <td>384.7398</td>\n",
       "      <td>383.8433</td>\n",
       "      <td>384.1325</td>\n",
       "      <td>8433936.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                date   1. open   2. high    3. low  4. close  \\\n",
       "104         104 2023-01-13 09:30:00  379.4570  380.9994  379.1871  380.5271   \n",
       "105         105 2023-01-13 10:00:00  380.5463  382.2912  380.1415  382.2237   \n",
       "106         106 2023-01-13 10:30:00  382.2334  382.4840  381.6164  382.1177   \n",
       "107         107 2023-01-13 11:00:00  382.1176  382.3105  381.1440  381.7417   \n",
       "108         108 2023-01-13 11:30:00  381.7610  381.8092  381.0091  381.5586   \n",
       "109         109 2023-01-13 12:00:00  381.5682  382.3201  381.4766  382.2141   \n",
       "110         110 2023-01-13 12:30:00  382.2141  382.5563  381.7706  382.4262   \n",
       "111         111 2023-01-13 13:00:00  382.4214  382.6383  381.8382  382.1851   \n",
       "112         112 2023-01-13 13:30:00  382.1852  383.3613  382.0695  383.2167   \n",
       "113         113 2023-01-13 14:00:00  383.2094  383.4577  382.8696  383.2745   \n",
       "114         114 2023-01-13 14:30:00  383.2842  383.5252  383.0142  383.3324   \n",
       "115         115 2023-01-13 15:00:00  383.3516  383.9686  383.2938  383.9499   \n",
       "116         116 2023-01-13 15:30:00  383.9686  384.7398  383.8433  384.1325   \n",
       "\n",
       "     5. volume  \n",
       "104  5376205.0  \n",
       "105  5289551.0  \n",
       "106  3208173.0  \n",
       "107  2821641.0  \n",
       "108  2337478.0  \n",
       "109  1774791.0  \n",
       "110  1741349.0  \n",
       "111  1930195.0  \n",
       "112  2834272.0  \n",
       "113  2496351.0  \n",
       "114  2667838.0  \n",
       "115  3092575.0  \n",
       "116  8433936.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_object = data.iloc[8*13:9*13]\n",
    "data_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81d9d22a-ab02-4927-a13f-a7227adcd3a4",
   "metadata": {
    "collapsed": true,
    "id": "0w7aIpptNTiH",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "close": {
          "bdata": "vVKWIQ6hgkDsUbgeBZqCQEw3iUFgnYJAzhlR2puhgkA/NV66yZqCQBfZzvdTnoJAPSzUmuajgkDxY8xdy6KCQKhXyjLEoYJAfGEyVTCjgkAzxLEubqaCQEmdgCbCpYJAiPTb1wGlgkA=",
          "dtype": "f8"
         },
         "high": {
          "bdata": "FK5H4fqjgkBSJ6CJMKOCQD55WKg1noJAgZVDi+yhgkDgnBGlPaKCQHicoiO5noJAFmpN8w6kgkCI9NvXAaWCQJ7vp8ZLpIJAHhZqTXOjgkCmCkYldaeCQEVHcvkPp4JA9wZfmEyngkA=",
          "dtype": "f8"
         },
         "low": {
          "bdata": "CmgibHicgkASFD/G3JmCQK5H4XoUmYJAayv2l92cgkABTYQNT5mCQPwYc9eSmoJA3bWEfNCdgkDhehSuR6KCQIQNT6+UoIJA6Ugu/6GfgkCjI7n8B6OCQE+vlGWIpIJACRueXimigkA=",
          "dtype": "f8"
         },
         "open": {
          "bdata": "RpT2Bl+hgkC9UpYhDqGCQJtVn6stmoJAfPKwUGudgkAeFmpNc6GCQISezarPmoJAP1dbsT+egkA9LNSa5qOCQEJg5dCiooJA0NVW7K+hgkCjI7n8B6OCQDEIrBxapoJAcvkP6belgkA=",
          "dtype": "f8"
         },
         "type": "candlestick",
         "x": [
          "2024-12-03T09:30:00.000000000",
          "2024-12-03T10:00:00.000000000",
          "2024-12-03T10:30:00.000000000",
          "2024-12-03T11:00:00.000000000",
          "2024-12-03T11:30:00.000000000",
          "2024-12-03T12:00:00.000000000",
          "2024-12-03T12:30:00.000000000",
          "2024-12-03T13:00:00.000000000",
          "2024-12-03T13:30:00.000000000",
          "2024-12-03T14:00:00.000000000",
          "2024-12-03T14:30:00.000000000",
          "2024-12-03T15:00:00.000000000",
          "2024-12-03T15:30:00.000000000"
         ],
         "xaxis": "x",
         "yaxis": "y"
        },
        {
         "close": {
          "bdata": "S+oENBG/eED7OnDOiNd4QMrDQq1p0HhAryXkg57YeEBqvHSTGNt4QEi/fR044nhApgpGJXXjeECpE9BE2Ol4QH0/NV669XhA24r9Zff8eEDfT42XbgN5QDeJQWDlA3lAfT81XroBeUA=",
          "dtype": "f8"
         },
         "high": {
          "bdata": "zhlR2hvFeEBfmEwVjNl4QGRd3EYD2nhAXkvIBz3ZeEDOGVHaG914QP32deCc43hArWnecYrkeECXkA96Nu14QN9PjZdu93hAKA8LtaYBeUCTGARWDgV5QPd14JwRB3lAqRPQRNgHeUA=",
          "dtype": "f8"
         },
         "low": {
          "bdata": "KqkT0ES4eEDjpZvEILx4QGKh1jTvzXhAyAc9m1XQeEAoDwu1ptF4QGq8dJMY23hAKxiV1AneeEB6Nqs+V914QH/7OnDO53hAcM6I0t7zeECb5h2n6Pl4QBHHuriN/nhAW0I+6Nn8eEA=",
          "dtype": "f8"
         },
         "open": {
          "bdata": "ryXkg57AeEBNFYxK6r54QKkT0ETY13hAyAc9m1XQeECvJeSDnth4QGq8dJMY23hASL99HTjieECmCkYldeN4QClcj8L16XhA1CtlGeL1eEBbQj7o2fx4QDSAt0CCA3lAjLlrCfkDeUA=",
          "dtype": "f8"
         },
         "type": "candlestick",
         "x": [
          "2023-04-13T09:30:00.000000000",
          "2023-04-13T10:00:00.000000000",
          "2023-04-13T10:30:00.000000000",
          "2023-04-13T11:00:00.000000000",
          "2023-04-13T11:30:00.000000000",
          "2023-04-13T12:00:00.000000000",
          "2023-04-13T12:30:00.000000000",
          "2023-04-13T13:00:00.000000000",
          "2023-04-13T13:30:00.000000000",
          "2023-04-13T14:00:00.000000000",
          "2023-04-13T14:30:00.000000000",
          "2023-04-13T15:00:00.000000000",
          "2023-04-13T15:30:00.000000000"
         ],
         "xaxis": "x2",
         "yaxis": "y2"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.475
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.525,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ]
        }
       }
      },
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "target1 = 482\n",
    "target2 = 69\n",
    "\n",
    "data_object = data.iloc[target1*13 : (target1 + 1)*13]\n",
    "data_object2 = data.iloc[target2*13 : (target2 + 1)*13]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    shared_yaxes=False,\n",
    "    horizontal_spacing=0.05\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Candlestick(x=data_object['date'],open=data_object['1. open'],high=data_object['2. high'],low=data_object['3. low'],close=data_object['4. close']), row=1, col=1)\n",
    "fig.add_trace(go.Candlestick(x=data_object2['date'],open=data_object2['1. open'],high=data_object2['2. high'],low=data_object2['3. low'],close=data_object2['4. close']), row=1, col=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b64bf83-8e3b-49e4-a6f4-eaa0791dcd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "489b5bab-aefe-48c1-87dc-cfb90719e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "105acfa6-2125-4b97-a8b8-a217d6cea0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[0.5408, 0.5374, 0.2823, 0.5051, 0.6122, 0.9354, 0.8844, 0.7398, 0.8214,\n",
      "         0.7245, 0.2551, 0.5544, 0.4694],\n",
      "        [0.7092, 0.7262, 0.5059, 0.6275, 1.0000, 0.9600, 0.9762, 0.8674, 0.9065,\n",
      "         0.9456, 0.5697, 0.6939, 0.6786],\n",
      "        [0.3231, 0.0000, 0.1462, 0.3930, 0.6122, 0.8639, 0.7364, 0.6207, 0.6718,\n",
      "         0.2041, 0.1939, 0.4456, 0.2068],\n",
      "        [0.5493, 0.2806, 0.5059, 0.6090, 0.9320, 0.8835, 0.7381, 0.8214, 0.7041,\n",
      "         0.2534, 0.5493, 0.4702, 0.6361],\n",
      "        [0.4810, 0.5997, 0.1571, 0.1495, 0.4042, 0.0804, 0.0177, 0.1493, 0.0000,\n",
      "         0.8152, 0.3566, 0.2410, 1.0000]]), 'idx': 1}\n"
     ]
    }
   ],
   "source": [
    "print(ds[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f19f04-dfa6-411d-aa31-df8a7a3d687d",
   "metadata": {},
   "source": [
    "# New Concatenation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6cc23c93-751f-4d18-b389-e0e8ab97538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fbd28204-1258-46e0-8230-36c53458a2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>code</th>\n",
       "      <th>z_0</th>\n",
       "      <th>z_1</th>\n",
       "      <th>z_2</th>\n",
       "      <th>z_3</th>\n",
       "      <th>z_4</th>\n",
       "      <th>z_5</th>\n",
       "      <th>z_6</th>\n",
       "      <th>z_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>25</td>\n",
       "      <td>0.021594</td>\n",
       "      <td>0.189350</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>0.094773</td>\n",
       "      <td>-9.261945e-28</td>\n",
       "      <td>0.034962</td>\n",
       "      <td>0.401183</td>\n",
       "      <td>0.569945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>12</td>\n",
       "      <td>0.102584</td>\n",
       "      <td>0.253331</td>\n",
       "      <td>0.088687</td>\n",
       "      <td>0.262031</td>\n",
       "      <td>1.646256e-24</td>\n",
       "      <td>0.050349</td>\n",
       "      <td>0.120076</td>\n",
       "      <td>0.256553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>9</td>\n",
       "      <td>0.034468</td>\n",
       "      <td>0.032504</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.347086</td>\n",
       "      <td>-1.079616e-28</td>\n",
       "      <td>0.339522</td>\n",
       "      <td>0.439623</td>\n",
       "      <td>0.407905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>7</td>\n",
       "      <td>0.190114</td>\n",
       "      <td>0.087750</td>\n",
       "      <td>0.160866</td>\n",
       "      <td>0.387595</td>\n",
       "      <td>-1.205483e-27</td>\n",
       "      <td>0.435344</td>\n",
       "      <td>0.160252</td>\n",
       "      <td>0.076243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>16</td>\n",
       "      <td>0.111109</td>\n",
       "      <td>0.432911</td>\n",
       "      <td>0.087223</td>\n",
       "      <td>0.046769</td>\n",
       "      <td>5.278745e-22</td>\n",
       "      <td>0.038995</td>\n",
       "      <td>0.109769</td>\n",
       "      <td>0.296704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2024-12-24</td>\n",
       "      <td>18</td>\n",
       "      <td>0.247099</td>\n",
       "      <td>0.285105</td>\n",
       "      <td>0.219507</td>\n",
       "      <td>0.215229</td>\n",
       "      <td>1.021299e-29</td>\n",
       "      <td>0.226921</td>\n",
       "      <td>0.026946</td>\n",
       "      <td>0.065848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2024-12-26</td>\n",
       "      <td>18</td>\n",
       "      <td>0.247099</td>\n",
       "      <td>0.285105</td>\n",
       "      <td>0.219507</td>\n",
       "      <td>0.215229</td>\n",
       "      <td>1.021299e-29</td>\n",
       "      <td>0.226921</td>\n",
       "      <td>0.026946</td>\n",
       "      <td>0.065848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>25</td>\n",
       "      <td>0.021594</td>\n",
       "      <td>0.189350</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>0.094773</td>\n",
       "      <td>-9.261945e-28</td>\n",
       "      <td>0.034962</td>\n",
       "      <td>0.401183</td>\n",
       "      <td>0.569945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.190114</td>\n",
       "      <td>0.087750</td>\n",
       "      <td>0.160866</td>\n",
       "      <td>0.387595</td>\n",
       "      <td>-1.205483e-27</td>\n",
       "      <td>0.435344</td>\n",
       "      <td>0.160252</td>\n",
       "      <td>0.076243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>25</td>\n",
       "      <td>0.021594</td>\n",
       "      <td>0.189350</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>0.094773</td>\n",
       "      <td>-9.261945e-28</td>\n",
       "      <td>0.034962</td>\n",
       "      <td>0.401183</td>\n",
       "      <td>0.569945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  code       z_0       z_1       z_2       z_3           z_4  \\\n",
       "0    2023-01-03    25  0.021594  0.189350  0.005870  0.094773 -9.261945e-28   \n",
       "1    2023-01-04    12  0.102584  0.253331  0.088687  0.262031  1.646256e-24   \n",
       "2    2023-01-05     9  0.034468  0.032504  0.005644  0.347086 -1.079616e-28   \n",
       "3    2023-01-06     7  0.190114  0.087750  0.160866  0.387595 -1.205483e-27   \n",
       "4    2023-01-09    16  0.111109  0.432911  0.087223  0.046769  5.278745e-22   \n",
       "..          ...   ...       ...       ...       ...       ...           ...   \n",
       "497  2024-12-24    18  0.247099  0.285105  0.219507  0.215229  1.021299e-29   \n",
       "498  2024-12-26    18  0.247099  0.285105  0.219507  0.215229  1.021299e-29   \n",
       "499  2024-12-27    25  0.021594  0.189350  0.005870  0.094773 -9.261945e-28   \n",
       "500  2024-12-30     7  0.190114  0.087750  0.160866  0.387595 -1.205483e-27   \n",
       "501  2024-12-31    25  0.021594  0.189350  0.005870  0.094773 -9.261945e-28   \n",
       "\n",
       "          z_5       z_6       z_7  \n",
       "0    0.034962  0.401183  0.569945  \n",
       "1    0.050349  0.120076  0.256553  \n",
       "2    0.339522  0.439623  0.407905  \n",
       "3    0.435344  0.160252  0.076243  \n",
       "4    0.038995  0.109769  0.296704  \n",
       "..        ...       ...       ...  \n",
       "497  0.226921  0.026946  0.065848  \n",
       "498  0.226921  0.026946  0.065848  \n",
       "499  0.034962  0.401183  0.569945  \n",
       "500  0.435344  0.160252  0.076243  \n",
       "501  0.034962  0.401183  0.569945  \n",
       "\n",
       "[502 rows x 10 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_path = \"prepared_data/embedding.csv\"\n",
    "embedding_df = pd.read_csv(embedding_path)\n",
    "embedding_df[\"date\"] = pd.to_datetime(embedding_df[\"date\"]).dt.date\n",
    "embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b01b30d0-7041-46cb-a32c-918cf6ab5059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Sony to launch PlayStation 5 in India on Febru...</td>\n",
       "      <td>Sony to launch PlayStation 5 in India on Febru...</td>\n",
       "      <td>The Japanese firm said it will begin taking pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Sony is launching the PS5 in India on February...</td>\n",
       "      <td>Sony is launching the PS5 in India on February...</td>\n",
       "      <td>PlayStation gamers in India will finally have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Huawei removes Tencent games from its Chinese ...</td>\n",
       "      <td>Huawei removes Tencent games from its Chinese ...</td>\n",
       "      <td>Huawei has pulled Tencent games like Arena of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Stadia Pro adds 'F1 2020' and 'Hotline Miami'\\...</td>\n",
       "      <td>Stadia Pro adds 'F1 2020' and 'Hotline Miami'</td>\n",
       "      <td>To ring in the new year, Google has added four...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>A workout-at-home service report card\\n\\nHere'...</td>\n",
       "      <td>A workout-at-home service report card</td>\n",
       "      <td>Here's how a number of at-home workout service...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66148</th>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>Mark Zuckerberg Is Reportedly Building an Unde...</td>\n",
       "      <td>Mark Zuckerberg Is Reportedly Building an Unde...</td>\n",
       "      <td>Meta's Mark Zuckerberg and his wife Priscilla ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66149</th>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>Ozempic drugmaker to open AI research hub in K...</td>\n",
       "      <td>Ozempic drugmaker to open AI research hub in K...</td>\n",
       "      <td>Novo Nordisk is poised to open a new AI resear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66150</th>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>Colombia Should Lower 35% Corporate Tax Rate, ...</td>\n",
       "      <td>Colombia Should Lower 35% Corporate Tax Rate, ...</td>\n",
       "      <td>(Bloomberg) -- Colombia President Gustavo Petr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66151</th>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>Nvidia Stock Has This Under-the-Radar Artifici...</td>\n",
       "      <td>Nvidia Stock Has This Under-the-Radar Artifici...</td>\n",
       "      <td>Nvidia stock investors are all focused on the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66152</th>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>2 Unstoppable Artificial Intelligence (AI) Sto...</td>\n",
       "      <td>2 Unstoppable Artificial Intelligence (AI) Sto...</td>\n",
       "      <td>Giants like Microsoft and Amazon aren't the on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66153 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date                                               text  \\\n",
       "0      2021-01-01  Sony to launch PlayStation 5 in India on Febru...   \n",
       "1      2021-01-01  Sony is launching the PS5 in India on February...   \n",
       "2      2021-01-01  Huawei removes Tencent games from its Chinese ...   \n",
       "3      2021-01-01  Stadia Pro adds 'F1 2020' and 'Hotline Miami'\\...   \n",
       "4      2021-01-01  A workout-at-home service report card\\n\\nHere'...   \n",
       "...           ...                                                ...   \n",
       "66148  2023-12-30  Mark Zuckerberg Is Reportedly Building an Unde...   \n",
       "66149  2023-12-30  Ozempic drugmaker to open AI research hub in K...   \n",
       "66150  2023-12-30  Colombia Should Lower 35% Corporate Tax Rate, ...   \n",
       "66151  2023-12-30  Nvidia Stock Has This Under-the-Radar Artifici...   \n",
       "66152  2023-12-30  2 Unstoppable Artificial Intelligence (AI) Sto...   \n",
       "\n",
       "                                                   title  \\\n",
       "0      Sony to launch PlayStation 5 in India on Febru...   \n",
       "1      Sony is launching the PS5 in India on February...   \n",
       "2      Huawei removes Tencent games from its Chinese ...   \n",
       "3          Stadia Pro adds 'F1 2020' and 'Hotline Miami'   \n",
       "4                  A workout-at-home service report card   \n",
       "...                                                  ...   \n",
       "66148  Mark Zuckerberg Is Reportedly Building an Unde...   \n",
       "66149  Ozempic drugmaker to open AI research hub in K...   \n",
       "66150  Colombia Should Lower 35% Corporate Tax Rate, ...   \n",
       "66151  Nvidia Stock Has This Under-the-Radar Artifici...   \n",
       "66152  2 Unstoppable Artificial Intelligence (AI) Sto...   \n",
       "\n",
       "                                                    body  \n",
       "0      The Japanese firm said it will begin taking pr...  \n",
       "1      PlayStation gamers in India will finally have ...  \n",
       "2      Huawei has pulled Tencent games like Arena of ...  \n",
       "3      To ring in the new year, Google has added four...  \n",
       "4      Here's how a number of at-home workout service...  \n",
       "...                                                  ...  \n",
       "66148  Meta's Mark Zuckerberg and his wife Priscilla ...  \n",
       "66149  Novo Nordisk is poised to open a new AI resear...  \n",
       "66150  (Bloomberg) -- Colombia President Gustavo Petr...  \n",
       "66151  Nvidia stock investors are all focused on the ...  \n",
       "66152  Giants like Microsoft and Amazon aren't the on...  \n",
       "\n",
       "[66153 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_path = \"processed_news.csv\"\n",
    "news_df = pd.read_csv(news_path)\n",
    "news_df[\"date\"] = pd.to_datetime(news_df[\"date\"]).dt.date\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "333b559a-887f-4e88-bd89-b5817451c4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>[Sony to launch PlayStation 5 in India on Febr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>['Apex Legends' Fight Night event formalizes i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>[Mixtape podcast: Behind the curtain of divers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>[Known for 5G mmWave testing solutions, Taiwan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>[Twitter is buying a podcast app to help build...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>[Forsaken China Stocks Get a New Look by Top E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>[Up Over 80%, Is Amazon Stock a Buy for 2024?\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>[Did Your Holiday Shopping Follow National Tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>[13 Best IPO Stocks to Buy Heading into 2024\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>[Taboola.com Ltd CTO Lior Golan Sells 60,000 S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>948 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                               text\n",
       "0    2021-01-01  [Sony to launch PlayStation 5 in India on Febr...\n",
       "1    2021-01-02  ['Apex Legends' Fight Night event formalizes i...\n",
       "2    2021-01-03  [Mixtape podcast: Behind the curtain of divers...\n",
       "3    2021-01-04  [Known for 5G mmWave testing solutions, Taiwan...\n",
       "4    2021-01-05  [Twitter is buying a podcast app to help build...\n",
       "..          ...                                                ...\n",
       "943  2023-12-20  [Forsaken China Stocks Get a New Look by Top E...\n",
       "944  2023-12-22  [Up Over 80%, Is Amazon Stock a Buy for 2024?\\...\n",
       "945  2023-12-26  [Did Your Holiday Shopping Follow National Tre...\n",
       "946  2023-12-27  [13 Best IPO Stocks to Buy Heading into 2024\\n...\n",
       "947  2023-12-30  [Taboola.com Ltd CTO Lior Golan Sells 60,000 S...\n",
       "\n",
       "[948 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_news_df = news_df.groupby(\"date\")[\"text\"].apply(list).reset_index()\n",
    "group_news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df2d4553-f47a-4539-aa44-d9d0766f8907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>[\"Sony to launch PlayStation 5 in India on Feb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>[\"'Apex Legends' Fight Night event formalizes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>[\"Mixtape podcast: Behind the curtain of diver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>[\"Known for 5G mmWave testing solutions, Taiwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>[\"Twitter is buying a podcast app to help buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>[\"Forsaken China Stocks Get a New Look by Top ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>[\"Up Over 80%, Is Amazon Stock a Buy for 2024?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>[\"Did Your Holiday Shopping Follow National Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>[\"13 Best IPO Stocks to Buy Heading into 2024\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>[\"Taboola.com Ltd CTO Lior Golan Sells 60,000 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>948 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                               text\n",
       "0    2021-01-01  [\"Sony to launch PlayStation 5 in India on Feb...\n",
       "1    2021-01-02  [\"'Apex Legends' Fight Night event formalizes ...\n",
       "2    2021-01-03  [\"Mixtape podcast: Behind the curtain of diver...\n",
       "3    2021-01-04  [\"Known for 5G mmWave testing solutions, Taiwa...\n",
       "4    2021-01-05  [\"Twitter is buying a podcast app to help buil...\n",
       "..          ...                                                ...\n",
       "943  2023-12-20  [\"Forsaken China Stocks Get a New Look by Top ...\n",
       "944  2023-12-22  [\"Up Over 80%, Is Amazon Stock a Buy for 2024?...\n",
       "945  2023-12-26  [\"Did Your Holiday Shopping Follow National Tr...\n",
       "946  2023-12-27  [\"13 Best IPO Stocks to Buy Heading into 2024\\...\n",
       "947  2023-12-30  [\"Taboola.com Ltd CTO Lior Golan Sells 60,000 ...\n",
       "\n",
       "[948 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_news_df[\"text\"] = group_news_df[\"text\"].apply(json.dumps)\n",
    "group_news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af8fc554-0b4c-413a-92ee-5fef32bf7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = embedding_df.merge(group_news_df, on=\"date\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53f38e45-3200-4695-91c5-a49dcef96ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>code</th>\n",
       "      <th>z_0</th>\n",
       "      <th>z_1</th>\n",
       "      <th>z_2</th>\n",
       "      <th>z_3</th>\n",
       "      <th>z_4</th>\n",
       "      <th>z_5</th>\n",
       "      <th>z_6</th>\n",
       "      <th>z_7</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>25</td>\n",
       "      <td>0.021594</td>\n",
       "      <td>0.189350</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>0.094773</td>\n",
       "      <td>-9.261945e-28</td>\n",
       "      <td>0.034962</td>\n",
       "      <td>0.401183</td>\n",
       "      <td>0.569945</td>\n",
       "      <td>[\"INFOLOB Solutions, Inc. Announces Company Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>12</td>\n",
       "      <td>0.102584</td>\n",
       "      <td>0.253331</td>\n",
       "      <td>0.088687</td>\n",
       "      <td>0.262031</td>\n",
       "      <td>1.646256e-24</td>\n",
       "      <td>0.050349</td>\n",
       "      <td>0.120076</td>\n",
       "      <td>0.256553</td>\n",
       "      <td>[\"Rover Metals Announces Intent to Re-price Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>9</td>\n",
       "      <td>0.034468</td>\n",
       "      <td>0.032504</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.347086</td>\n",
       "      <td>-1.079616e-28</td>\n",
       "      <td>0.339522</td>\n",
       "      <td>0.439623</td>\n",
       "      <td>0.407905</td>\n",
       "      <td>[\"Innovent Announces NMPA's Breakthrough Thera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>7</td>\n",
       "      <td>0.190114</td>\n",
       "      <td>0.087750</td>\n",
       "      <td>0.160866</td>\n",
       "      <td>0.387595</td>\n",
       "      <td>-1.205483e-27</td>\n",
       "      <td>0.435344</td>\n",
       "      <td>0.160252</td>\n",
       "      <td>0.076243</td>\n",
       "      <td>[\"VRSim Hosts Senator Murphy at East Hartford ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>16</td>\n",
       "      <td>0.111109</td>\n",
       "      <td>0.432911</td>\n",
       "      <td>0.087223</td>\n",
       "      <td>0.046769</td>\n",
       "      <td>5.278745e-22</td>\n",
       "      <td>0.038995</td>\n",
       "      <td>0.109769</td>\n",
       "      <td>0.296704</td>\n",
       "      <td>[\"Esperion Outlines Upcoming Milestones and An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>18</td>\n",
       "      <td>0.247099</td>\n",
       "      <td>0.285105</td>\n",
       "      <td>0.219507</td>\n",
       "      <td>0.215229</td>\n",
       "      <td>1.021299e-29</td>\n",
       "      <td>0.226921</td>\n",
       "      <td>0.026946</td>\n",
       "      <td>0.065848</td>\n",
       "      <td>[\"Here's Why I Just Sold These 2 Blue-Chip Sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>16</td>\n",
       "      <td>0.111109</td>\n",
       "      <td>0.432911</td>\n",
       "      <td>0.087223</td>\n",
       "      <td>0.046769</td>\n",
       "      <td>5.278745e-22</td>\n",
       "      <td>0.038995</td>\n",
       "      <td>0.109769</td>\n",
       "      <td>0.296704</td>\n",
       "      <td>[\"Forsaken China Stocks Get a New Look by Top ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>16</td>\n",
       "      <td>0.111109</td>\n",
       "      <td>0.432911</td>\n",
       "      <td>0.087223</td>\n",
       "      <td>0.046769</td>\n",
       "      <td>5.278745e-22</td>\n",
       "      <td>0.038995</td>\n",
       "      <td>0.109769</td>\n",
       "      <td>0.296704</td>\n",
       "      <td>[\"Up Over 80%, Is Amazon Stock a Buy for 2024?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>9</td>\n",
       "      <td>0.034468</td>\n",
       "      <td>0.032504</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.347086</td>\n",
       "      <td>-1.079616e-28</td>\n",
       "      <td>0.339522</td>\n",
       "      <td>0.439623</td>\n",
       "      <td>0.407905</td>\n",
       "      <td>[\"Did Your Holiday Shopping Follow National Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>12</td>\n",
       "      <td>0.102584</td>\n",
       "      <td>0.253331</td>\n",
       "      <td>0.088687</td>\n",
       "      <td>0.262031</td>\n",
       "      <td>1.646256e-24</td>\n",
       "      <td>0.050349</td>\n",
       "      <td>0.120076</td>\n",
       "      <td>0.256553</td>\n",
       "      <td>[\"13 Best IPO Stocks to Buy Heading into 2024\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  code       z_0       z_1       z_2       z_3           z_4  \\\n",
       "0    2023-01-03    25  0.021594  0.189350  0.005870  0.094773 -9.261945e-28   \n",
       "1    2023-01-04    12  0.102584  0.253331  0.088687  0.262031  1.646256e-24   \n",
       "2    2023-01-05     9  0.034468  0.032504  0.005644  0.347086 -1.079616e-28   \n",
       "3    2023-01-06     7  0.190114  0.087750  0.160866  0.387595 -1.205483e-27   \n",
       "4    2023-01-09    16  0.111109  0.432911  0.087223  0.046769  5.278745e-22   \n",
       "..          ...   ...       ...       ...       ...       ...           ...   \n",
       "221  2023-12-19    18  0.247099  0.285105  0.219507  0.215229  1.021299e-29   \n",
       "222  2023-12-20    16  0.111109  0.432911  0.087223  0.046769  5.278745e-22   \n",
       "223  2023-12-22    16  0.111109  0.432911  0.087223  0.046769  5.278745e-22   \n",
       "224  2023-12-26     9  0.034468  0.032504  0.005644  0.347086 -1.079616e-28   \n",
       "225  2023-12-27    12  0.102584  0.253331  0.088687  0.262031  1.646256e-24   \n",
       "\n",
       "          z_5       z_6       z_7  \\\n",
       "0    0.034962  0.401183  0.569945   \n",
       "1    0.050349  0.120076  0.256553   \n",
       "2    0.339522  0.439623  0.407905   \n",
       "3    0.435344  0.160252  0.076243   \n",
       "4    0.038995  0.109769  0.296704   \n",
       "..        ...       ...       ...   \n",
       "221  0.226921  0.026946  0.065848   \n",
       "222  0.038995  0.109769  0.296704   \n",
       "223  0.038995  0.109769  0.296704   \n",
       "224  0.339522  0.439623  0.407905   \n",
       "225  0.050349  0.120076  0.256553   \n",
       "\n",
       "                                                  text  \n",
       "0    [\"INFOLOB Solutions, Inc. Announces Company Re...  \n",
       "1    [\"Rover Metals Announces Intent to Re-price Pr...  \n",
       "2    [\"Innovent Announces NMPA's Breakthrough Thera...  \n",
       "3    [\"VRSim Hosts Senator Murphy at East Hartford ...  \n",
       "4    [\"Esperion Outlines Upcoming Milestones and An...  \n",
       "..                                                 ...  \n",
       "221  [\"Here's Why I Just Sold These 2 Blue-Chip Sto...  \n",
       "222  [\"Forsaken China Stocks Get a New Look by Top ...  \n",
       "223  [\"Up Over 80%, Is Amazon Stock a Buy for 2024?...  \n",
       "224  [\"Did Your Holiday Shopping Follow National Tr...  \n",
       "225  [\"13 Best IPO Stocks to Buy Heading into 2024\\...  \n",
       "\n",
       "[226 rows x 11 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cdf47286-558b-4c82-b5ae-1a789ccff141",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_path = \"prepared_data/final.csv\"\n",
    "final_df.to_csv(final_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e78d6-599f-4462-b04d-1f4f53d99158",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Silver Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759d1e33-13c2-4d99-892e-2d3477af92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google import genai\n",
    "from google.genai.errors import APIError\n",
    "import time\n",
    "\n",
    "# --- 1. 설정 및 초기화 ---\n",
    "\n",
    "# ⚠️ 여기에 실제 Gemini API 키를 입력하세요.\n",
    "# 환경 변수를 사용하는 것을 권장하지만, 테스트를 위해 직접 입력할 수도 있습니다.\n",
    "API_KEY = \"AIzaSyC4s-EgCqUKKn5eVwnpx-7DlvDVdAp5qkw\"\n",
    "try:\n",
    "    # client 객체는 for 루프 밖에서 한 번만 초기화됩니다.\n",
    "    client = genai.Client(api_key=API_KEY)\n",
    "    model = 'gemini-2.5-flash'  # 빠른 응답을 위해 flash 모델 사용\n",
    "except Exception as e:\n",
    "    print(f\"Gemini 클라이언트 초기화 오류: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. 데이터 로드 ---\n",
    "\n",
    "file_path = 'prepared_data/final.csv'\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"✅ 파일 '{file_path}' 로드 완료. 총 {len(df)}개 행.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ 오류: 파일 '{file_path}'를 찾을 수 없습니다. 경로를 확인해주세요.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"❌ 오류: CSV 파일을 읽는 중 문제가 발생했습니다: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 그룹화할 키 컬럼\n",
    "GROUPING_KEY = 'code'\n",
    "\n",
    "if GROUPING_KEY not in df.columns:\n",
    "    print(f\"❌ 오류: 데이터프레임에 그룹화 키인 '{GROUPING_KEY}' 열이 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Silver Label 생성을 위한 함수 정의 ---\n",
    "\n",
    "def generate_silver_label(text_list, code_value, client_obj, model_name, prompt_input):\n",
    "    \"\"\"\n",
    "    주어진 텍스트 리스트를 Gemini API를 사용하여 요약합니다.\n",
    "    (API 클라이언트 객체를 인수로 받도록 수정)\n",
    "    \"\"\"\n",
    "    if not text_list:\n",
    "        return \"\"\n",
    "\n",
    "    # 텍스트들을 하나의 문자열로 결합\n",
    "    combined_text = \"\\n---\\n\".join(text_list)\n",
    "    combined_text = combined_text[:100000]\n",
    "    # 프롬프트 정의\n",
    "    prompt = f\"\"\"\n",
    "    아래에 제공된 텍스트들은 공통적으로 코드 값 {code_value}를 가지는 뉴스 기사/정보의 일부입니다.\n",
    "    \n",
    "    이 모든 텍스트의 핵심 내용과 주제를 파악하여, 100~200자 사이의 하나의 **한국어 요약(Silver Label)**으로 정리해 주세요.\n",
    "    요약은 다음 형식을 따릅니다: \"핵심 주제: (핵심 내용)\"\n",
    "    \n",
    "    --- 텍스트 목록 ---\n",
    "    {combined_text}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Gemini API 호출\n",
    "        response = client_obj.models.generate_content(\n",
    "            model=model_name,\n",
    "            contents=prompt\n",
    "        )\n",
    "        return response.text.strip()\n",
    "    \n",
    "    # 토큰 만료 또는 기타 API 오류 발생 시\n",
    "    except APIError as e:\n",
    "        # 오류 상세 정보를 반환하여 나중에 원인을 분석할 수 있게 함\n",
    "        return f\"요약 오류: API Error - {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"요약 오류: Unexpected Error - {e}\"\n",
    "\n",
    "# --- 4. 그룹별 요약 및 Silver Label 생성 (지연/반복문 적용) ---\n",
    "\n",
    "# GROUPING_KEY를 기준으로 그룹화\n",
    "grouped = df.groupby(GROUPING_KEY)['text'].apply(list).reset_index(name='text_list')\n",
    "print(f\"⚙️ {GROUPING_KEY} 값 {len(grouped)}개로 그룹화 완료.\")\n",
    "\n",
    "# 'silver_label' 열을 미리 초기화합니다.\n",
    "grouped['silver_label'] = None \n",
    "\n",
    "print(\"✨ 그룹별 Silver Label 생성 중... (API 호출 사이에 **1분 지연**이 적용됩니다.)\")\n",
    "\n",
    "# 인덱스를 리스트로 변환하여 마지막 인덱스를 쉽게 확인\n",
    "group_indices = grouped.index.tolist()\n",
    "total_groups = len(group_indices)\n",
    "\n",
    "\n",
    "prompts = [\n",
    "  {\n",
    "    \"prompt_number\": 1,\n",
    "    \"prompt_context\": \"상세 분석 및 항목 강제: 요약에 반드시 '주요 산업 분야/기술 트렌드', '주요 이슈/활동 유형', '전반적인 시장 분위기/영향' 세 가지 요소를 포함하도록 강제하여 구체적인 분석 데이터를 확보합니다.\",\n",
    "    \"prompt_text\": \"아래 제공된 텍스트들은 공통적으로 코드 값 {code_value}를 가지는 뉴스 기사/정보의 일부입니다.\\n\\n당신은 전문 뉴스 분석가입니다. 이 모든 텍스트를 분석하여, 다음 세 가지 핵심 항목을 반드시 포함하는 100~200자 사이의 하나의 **한국어 요약(Silver Label)**으로 정리해 주세요.\\n\\n1. **언급된 주요 산업 분야 또는 기술 트렌드** (예: IT, 헬스케어, ESG, AI 등)\\n2. **주요 이슈/활동의 유형** (예: 인수합병, 신제품 출시, 실적 발표, 정책 변화 등)\\n3. **전반적인 시장 분위기 또는 영향** (예: 성장 기대, 불확실성 증대, 규제 강화 등)\\n\\n요약은 반드시 다음 형식을 따르며, 구체적이어야 합니다:\\n\\\"핵심 주제: (핵심 내용. 위 3가지 항목이 모두 녹아 있어야 함)\\\"\\n\\n--- 텍스트 목록 ---\\n{combined_text}\",\n",
    "    \"output_name\": \"silver_label_detailed_analysis.csv\"\n",
    "  },\n",
    "  {\n",
    "    \"prompt_number\": 2,\n",
    "    \"prompt_context\": \"시장 동향 중심 요약: 개별 기업 활동보다는 거시적 관점의 '시장 변화'와 '위험 요소'에 초점을 맞춰 요약하도록 유도하여 트렌드 레이블을 추출합니다.\",\n",
    "    \"prompt_text\": \"아래 제공된 텍스트들은 공통적으로 코드 값 {code_value}를 가지는 뉴스 기사/정보의 일부입니다.\\n\\n이 모든 텍스트를 기반으로, 해당 코드와 관련된 **가장 중요한 거시적 시장 동향**과 **잠재적 위험/기회 요소**를 100~200자 사이의 하나의 **한국어 요약(Silver Label)**으로 정리해 주세요.\\n\\n**[핵심 요구사항]**\\n1. **경제 환경/정책 변화**가 포함되어야 합니다.\\n2. **개별 기업명 언급은 최소화**하고 산업 전반의 방향성을 제시해야 합니다.\\n\\n요약 형식: \\\"핵심 주제: (시장 변화와 주요 리스크/기회에 초점 맞춘 내용)\\\"\\n\\n--- 텍스트 목록 ---\\n{combined_text}\",\n",
    "    \"output_name\": \"silver_label_market_trend.csv\"\n",
    "  },\n",
    "  {\n",
    "    \"prompt_number\": 3,\n",
    "    \"prompt_context\": \"감성/태도 평가: 텍스트의 전반적인 분위기(긍정/부정/중립)를 파악하고, 그 근거가 되는 활동(투자 vs. 하락)을 명시하도록 요구하여 감성 데이터 레이블을 추출합니다.\",\n",
    "    \"prompt_text\": \"아래 제공된 텍스트들을 분석하여, 해당 코드 {code_value}와 관련된 활동의 **전반적인 감성(긍정/부정/중립)**을 파악하고 그 근거를 요약하세요.\\n\\n요약은 다음 네 가지 요소를 모두 포함하는 100~200자 사이의 하나의 **한국어 요약(Silver Label)**으로 정리해 주세요.\\n\\n1. **가장 빈번하게 언급된 기업 활동** (예: 성장, 투자, 하락, 구조조정)\\n2. **전반적인 감성 평가** (긍정, 부정, 또는 혼재)\\n3. **감성 평가의 근거**가 되는 주요 사건 (긍정적/부정적)\\n\\n요약 형식: \\\"핵심 주제: (전반적인 감성 평가와 그 근거를 명확히 제시한 내용)\\\"\\n\\n--- 텍스트 목록 ---\\n{combined_text}\",\n",
    "    \"output_name\": \"silver_label_sentiment_focus.csv\"\n",
    "  }\n",
    "]\n",
    "\n",
    "for index, p in enumerate(prompts):\n",
    "    concated_prompt = p[\"prompt_context\"] + p[\"prompt_text\"]\n",
    "\n",
    "# 반복문을 사용하여 한 줄씩 처리\n",
    "    for i, index in enumerate(group_indices):\n",
    "        row = grouped.loc[index]\n",
    "        text_list = row['text_list']\n",
    "        group_key = row[GROUPING_KEY]\n",
    "        \n",
    "        print(f\"\\n🚀 {i+1}/{total_groups} 처리 중 - Code: {group_key} (텍스트 {len(text_list)}개)\")\n",
    "\n",
    "        # 1. generate_silver_label 함수 호출\n",
    "        silver_label = generate_silver_label(text_list, group_key, client, model, concated_prompt)\n",
    "        \n",
    "        # 2. 결과 저장\n",
    "        grouped.loc[index, 'silver_label'] = silver_label\n",
    "    \n",
    "        if silver_label.startswith(\"요약 오류:\"):\n",
    "            print(f\"❌ 오류 발생: {silver_label}\")\n",
    "        else:\n",
    "            print(\"✅ Silver Label 생성 및 저장 완료.\")\n",
    "\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "    print(\"\\n✅ Silver Label 생성 완료.\")\n",
    "\n",
    "    # --- 5. 원본 데이터프레임에 Silver Label 병합 ---\n",
    "\n",
    "    # 병합을 위해 'silver_label'과 GROUPING_KEY만 포함하는 데이터프레임 준비\n",
    "    silver_labels_df = grouped[[GROUPING_KEY, 'silver_label']]\n",
    "\n",
    "    # 원본 데이터프레임에 병합\n",
    "    df_merged = pd.merge(df.drop(columns=['text']), silver_labels_df, on=GROUPING_KEY, how='left')\n",
    "\n",
    "    # 'silver_label'을 새 'text'로 사용하고 이름을 변경\n",
    "    df_merged.rename(columns={'silver_label': 'text'}, inplace=True)\n",
    "\n",
    "    # 열 순서 조정 (원본과 유사하게)\n",
    "    cols = list(df_merged.columns)\n",
    "    cols.remove('text')\n",
    "    df_final = df_merged[cols + ['text']]\n",
    "\n",
    "    # --- 6. 결과 저장 ---\n",
    "\n",
    "    output_file_path = p[\"output_name\"]\n",
    "    try:\n",
    "        df_final.to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "        print(f\"\\n🎉 최종 결과가 '{output_file_path}'에 저장되었습니다.\")\n",
    "        print(\"👉 이제 이 파일을 사용하여 후속 분석을 진행할 수 있습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류: 최종 CSV 파일 저장 중 문제가 발생했습니다: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8dd84a-a846-444e-a900-5ebefcad014a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42852a14-fc76-4274-85dd-a23366719810",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "\n",
    "# s3 기본 설정\n",
    "# BUCKET = \"sagemaker-us-west-2-327784329358\"\n",
    "# S3_BASE = f\"s3://{BUCKET}\"\n",
    "\n",
    "# 입력 데이터: S3에서 바로 읽기\n",
    "# PRICE_OHLCV_PATH = f\"{S3_BASE}/prepared_data/price_ohlcv.csv\"\n",
    "# VQ_CODE_CSV_PATH = f\"{S3_BASE}/vq_vae_outputs/vq_codes_spy.csv\"\n",
    "# NEWS_CSV_PATH = f\"{S3_BASE}/prepared_data/sp500_headlines_2008_2024.csv\"\n",
    "\n",
    "# 출력 JSONL: 로컬에 만들고 S3로 업로드\n",
    "# OUTPUT_JSONL_LOCAL_PATH = \"/tmp/market_commentary_train.jsonl\"\n",
    "# OUTPUT_JSONL_S3_KEY = \"prepared_data/market_commentary_train.jsonl\"\n",
    "\n",
    "# Data Path\n",
    "OUTPUT_JSONL_LOCAL_PATH = \"prepared_data/train.jsonl\"\n",
    "SILVER_LABEL_PATH = \"silver_label_market_trend.csv\"\n",
    "PRICE_OHLCV_PATH = \"spy_2023_2024.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8463c96a-2378-46a7-a297-d46ba12a7ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_silver_label = pd.read_csv(SILVER_LABEL_PATH)\n",
    "df_price = pd.read_csv(PRICE_OHLCV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d1b92b4-0fc4-4903-83f9-b5ac5117bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required_cols = {\"date\", \"close\"}\n",
    "# if not required_cols.issubset(df_price.columns):\n",
    "    # raise ValueError(\"prices_ohlcv.csv에 date, close 컬럼이 필요합니다.\")\n",
    "\n",
    "df_silver_label['date'] = pd.to_datetime(df_silver_label['date']).dt.date\n",
    "\n",
    "df_price['date'] = pd.to_datetime(df_price['date'])\n",
    "df_price['day'] = df_price['date'].dt.date\n",
    "df_price = df_price.groupby('day').tail(1)\n",
    "\n",
    "def make_summary(row):\n",
    "    return (\n",
    "        f\"open: {row['1. open']}, \"\n",
    "        f\"high: {row['2. high']}, \"\n",
    "        f\"low: {row['3. low']}, \"\n",
    "        f\"close: {row['4. close']}, \"\n",
    "        f\"volume: {row['5. volume']}\"\n",
    "    )\n",
    "\n",
    "df_price[\"ohlcv_summary\"] = df_price.apply(make_summary, axis=1)\n",
    "df_price = df_price[['day', 'ohlcv_summary']].copy()\n",
    "df_price = df_price.rename(columns={'day': 'date'})\n",
    "df_price['date'] = pd.to_datetime(df_price['date']).dt.date\n",
    "\n",
    "# df_price[\"date\"] = pd.to_datetime(df_price[\"date\"])\n",
    "# df_price = df_price.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# 여기서 수익률, 변동성 등 파생 피처 생성\n",
    "# df_price[\"ret_1d\"] = df_price[\"close\"].pct_change()\n",
    "# df_price[\"log_ret\"] = np.log(df_price[\"close\"]).diff()\n",
    "# df_price[\"close_ma_5\"] = df_price[\"close\"].rolling(window=5).mean()\n",
    "# df_price[\"close_ma_20\"] = df_price[\"close\"].rolling(window=20).mean()\n",
    "# df_price[\"vol_5\"] = df_price[\"log_ret\"].rolling(window=5).std()\n",
    "# df_price[\"vol_20\"] = df_price[\"log_ret\"].rolling(window=20).std()\n",
    "\n",
    "# NaN 제거\n",
    "# df_price = df_price.dropna().reset_index(drop=True)\n",
    "# print(\"[PRICE] head:\\n\", df_price.head())\n",
    "\n",
    "\n",
    "# VQ-VAE 코드와 price join\n",
    "# df_vq = pd.read_csv(VQ_CODE_CSV_PATH)\n",
    "# df_vq[\"date\"] = pd.to_datetime(df_vq[\"date\"])\n",
    "\n",
    "# df_merged = pd.merge(df_vq, df_price, on=\"date\", how=\"inner\")\n",
    "# df_merged = df_merged.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# News Headline join\n",
    "# df_news = pd.read_csv(\"NEWS_CSV_PATH\")\n",
    "# df_news[\"Date\"] = pd.to_datetime(df_news[\"Date\"])\n",
    "\n",
    "\"\"\" news_grouped = (\n",
    "    df_news.groupby(\"Date\")[\"Title\"]\n",
    "    .apply(list)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"Date\": \"date\", \"Title\": \"titles\"})\n",
    ") \"\"\"\n",
    "\n",
    "# merge all\n",
    "df_all = pd.merge(\n",
    "    df_silver_label,\n",
    "    df_price,                # VQ 코드 + 가격 요약\n",
    "    on=\"date\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4155c58-068f-41a1-b919-d98a75ec5932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_to_str(row):\n",
    "    z_values = [row[f\"z_{i}\"] for i in range(8)]\n",
    "    z_str = \", \".join([f\"{v:.6f}\" for v in z_values])\n",
    "    return f\"{z_str}\"\n",
    "\n",
    "df_all[\"code_str\"] = df_all.apply(code_to_str, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c500a0a-3cf2-4e10-9927-8006d34f8078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>code</th>\n",
       "      <th>z_0</th>\n",
       "      <th>z_1</th>\n",
       "      <th>z_2</th>\n",
       "      <th>z_3</th>\n",
       "      <th>z_4</th>\n",
       "      <th>z_5</th>\n",
       "      <th>z_6</th>\n",
       "      <th>z_7</th>\n",
       "      <th>text</th>\n",
       "      <th>ohlcv_summary</th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>code_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>25</td>\n",
       "      <td>0.021594</td>\n",
       "      <td>0.189350</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>0.094773</td>\n",
       "      <td>-9.261945e-28</td>\n",
       "      <td>0.034962</td>\n",
       "      <td>0.401183</td>\n",
       "      <td>0.569945</td>\n",
       "      <td>핵심 주제: 기업 경영, 시장 동향 및 신기술\\n다양한 기업들이 경영진 개편, M&amp;...</td>\n",
       "      <td>open: 366.6838, high: 367.5803, low: 366.6066,...</td>\n",
       "      <td>### 코드\\n25\\n\\n### OHLCV 시계열\\nopen: 366.6838, h...</td>\n",
       "      <td>핵심 주제: 기업 경영, 시장 동향 및 신기술\\n다양한 기업들이 경영진 개편, M&amp;...</td>\n",
       "      <td>0.021594, 0.189350, 0.005870, 0.094773, -0.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>12</td>\n",
       "      <td>0.102584</td>\n",
       "      <td>0.253331</td>\n",
       "      <td>0.088687</td>\n",
       "      <td>0.262031</td>\n",
       "      <td>1.646256e-24</td>\n",
       "      <td>0.050349</td>\n",
       "      <td>0.120076</td>\n",
       "      <td>0.256553</td>\n",
       "      <td>핵심 주제: 2023년 초 글로벌 비즈니스 및 기술 동향\\n\\n2023년 초 다양한...</td>\n",
       "      <td>open: 368.9878, high: 370.1735, low: 367.4996,...</td>\n",
       "      <td>### 코드\\n12\\n\\n### OHLCV 시계열\\nopen: 368.9878, h...</td>\n",
       "      <td>핵심 주제: 2023년 초 글로벌 비즈니스 및 기술 동향\\n\\n2023년 초 다양한...</td>\n",
       "      <td>0.102584, 0.253331, 0.088687, 0.262031, 0.0000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>9</td>\n",
       "      <td>0.034468</td>\n",
       "      <td>0.032504</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.347086</td>\n",
       "      <td>-1.079616e-28</td>\n",
       "      <td>0.339522</td>\n",
       "      <td>0.439623</td>\n",
       "      <td>0.407905</td>\n",
       "      <td>핵심 주제: 2023년 초 다양한 산업의 혁신 및 시장 동향: CES 2023을 통...</td>\n",
       "      <td>open: 365.9704, high: 366.2837, low: 365.2811,...</td>\n",
       "      <td>### 코드\\n9\\n\\n### OHLCV 시계열\\nopen: 365.9704, hi...</td>\n",
       "      <td>핵심 주제: 2023년 초 다양한 산업의 혁신 및 시장 동향: CES 2023을 통...</td>\n",
       "      <td>0.034468, 0.032504, 0.005644, 0.347086, -0.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>7</td>\n",
       "      <td>0.190114</td>\n",
       "      <td>0.087750</td>\n",
       "      <td>0.160866</td>\n",
       "      <td>0.387595</td>\n",
       "      <td>-1.205483e-27</td>\n",
       "      <td>0.435344</td>\n",
       "      <td>0.160252</td>\n",
       "      <td>0.076243</td>\n",
       "      <td>핵심 주제: 광범위한 산업의 시장 성장 전망, 기업의 재무 성과, 투자 및 자금 조...</td>\n",
       "      <td>open: 374.4007, high: 375.0707, low: 373.7789,...</td>\n",
       "      <td>### 코드\\n7\\n\\n### OHLCV 시계열\\nopen: 374.4007, hi...</td>\n",
       "      <td>핵심 주제: 광범위한 산업의 시장 성장 전망, 기업의 재무 성과, 투자 및 자금 조...</td>\n",
       "      <td>0.190114, 0.087750, 0.160866, 0.387595, -0.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>16</td>\n",
       "      <td>0.111109</td>\n",
       "      <td>0.432911</td>\n",
       "      <td>0.087223</td>\n",
       "      <td>0.046769</td>\n",
       "      <td>5.278745e-22</td>\n",
       "      <td>0.038995</td>\n",
       "      <td>0.109769</td>\n",
       "      <td>0.296704</td>\n",
       "      <td>핵심 주제: 글로벌 기업 경영 활동 및 시장 전망. 다양한 산업 분야에서 기업들의 ...</td>\n",
       "      <td>open: 374.3863, high: 374.5694, low: 373.7211,...</td>\n",
       "      <td>### 코드\\n16\\n\\n### OHLCV 시계열\\nopen: 374.3863, h...</td>\n",
       "      <td>핵심 주제: 글로벌 기업 경영 활동 및 시장 전망. 다양한 산업 분야에서 기업들의 ...</td>\n",
       "      <td>0.111109, 0.432911, 0.087223, 0.046769, 0.0000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  code       z_0       z_1       z_2       z_3           z_4  \\\n",
       "0  2023-01-03    25  0.021594  0.189350  0.005870  0.094773 -9.261945e-28   \n",
       "1  2023-01-04    12  0.102584  0.253331  0.088687  0.262031  1.646256e-24   \n",
       "2  2023-01-05     9  0.034468  0.032504  0.005644  0.347086 -1.079616e-28   \n",
       "3  2023-01-06     7  0.190114  0.087750  0.160866  0.387595 -1.205483e-27   \n",
       "4  2023-01-09    16  0.111109  0.432911  0.087223  0.046769  5.278745e-22   \n",
       "\n",
       "        z_5       z_6       z_7  \\\n",
       "0  0.034962  0.401183  0.569945   \n",
       "1  0.050349  0.120076  0.256553   \n",
       "2  0.339522  0.439623  0.407905   \n",
       "3  0.435344  0.160252  0.076243   \n",
       "4  0.038995  0.109769  0.296704   \n",
       "\n",
       "                                                text  \\\n",
       "0  핵심 주제: 기업 경영, 시장 동향 및 신기술\\n다양한 기업들이 경영진 개편, M&...   \n",
       "1  핵심 주제: 2023년 초 글로벌 비즈니스 및 기술 동향\\n\\n2023년 초 다양한...   \n",
       "2  핵심 주제: 2023년 초 다양한 산업의 혁신 및 시장 동향: CES 2023을 통...   \n",
       "3  핵심 주제: 광범위한 산업의 시장 성장 전망, 기업의 재무 성과, 투자 및 자금 조...   \n",
       "4  핵심 주제: 글로벌 기업 경영 활동 및 시장 전망. 다양한 산업 분야에서 기업들의 ...   \n",
       "\n",
       "                                       ohlcv_summary  \\\n",
       "0  open: 366.6838, high: 367.5803, low: 366.6066,...   \n",
       "1  open: 368.9878, high: 370.1735, low: 367.4996,...   \n",
       "2  open: 365.9704, high: 366.2837, low: 365.2811,...   \n",
       "3  open: 374.4007, high: 375.0707, low: 373.7789,...   \n",
       "4  open: 374.3863, high: 374.5694, low: 373.7211,...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  ### 코드\\n25\\n\\n### OHLCV 시계열\\nopen: 366.6838, h...   \n",
       "1  ### 코드\\n12\\n\\n### OHLCV 시계열\\nopen: 368.9878, h...   \n",
       "2  ### 코드\\n9\\n\\n### OHLCV 시계열\\nopen: 365.9704, hi...   \n",
       "3  ### 코드\\n7\\n\\n### OHLCV 시계열\\nopen: 374.4007, hi...   \n",
       "4  ### 코드\\n16\\n\\n### OHLCV 시계열\\nopen: 374.3863, h...   \n",
       "\n",
       "                                          completion  \\\n",
       "0  핵심 주제: 기업 경영, 시장 동향 및 신기술\\n다양한 기업들이 경영진 개편, M&...   \n",
       "1  핵심 주제: 2023년 초 글로벌 비즈니스 및 기술 동향\\n\\n2023년 초 다양한...   \n",
       "2  핵심 주제: 2023년 초 다양한 산업의 혁신 및 시장 동향: CES 2023을 통...   \n",
       "3  핵심 주제: 광범위한 산업의 시장 성장 전망, 기업의 재무 성과, 투자 및 자금 조...   \n",
       "4  핵심 주제: 글로벌 기업 경영 활동 및 시장 전망. 다양한 산업 분야에서 기업들의 ...   \n",
       "\n",
       "                                            code_str  \n",
       "0  0.021594, 0.189350, 0.005870, 0.094773, -0.000...  \n",
       "1  0.102584, 0.253331, 0.088687, 0.262031, 0.0000...  \n",
       "2  0.034468, 0.032504, 0.005644, 0.347086, -0.000...  \n",
       "3  0.190114, 0.087750, 0.160866, 0.387595, -0.000...  \n",
       "4  0.111109, 0.432911, 0.087223, 0.046769, 0.0000...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff55a629-3753-46b4-9ca2-592c3975a5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ALL with prompt/completion] head:\n",
      "          date  code                                             prompt  \\\n",
      "0  2023-01-03    25  ### 코드북\\n25\\n\\n### 코드북 벡터\\n0.021594, 0.189350,...   \n",
      "1  2023-01-04    12  ### 코드북\\n12\\n\\n### 코드북 벡터\\n0.102584, 0.253331,...   \n",
      "2  2023-01-05     9  ### 코드북\\n9\\n\\n### 코드북 벡터\\n0.034468, 0.032504, ...   \n",
      "3  2023-01-06     7  ### 코드북\\n7\\n\\n### 코드북 벡터\\n0.190114, 0.087750, ...   \n",
      "4  2023-01-09    16  ### 코드북\\n16\\n\\n### 코드북 벡터\\n0.111109, 0.432911,...   \n",
      "\n",
      "                                          completion  \n",
      "0  핵심 주제: 기업 경영, 시장 동향 및 신기술\\n다양한 기업들이 경영진 개편, M&...  \n",
      "1  핵심 주제: 2023년 초 글로벌 비즈니스 및 기술 동향\\n\\n2023년 초 다양한...  \n",
      "2  핵심 주제: 2023년 초 다양한 산업의 혁신 및 시장 동향: CES 2023을 통...  \n",
      "3  핵심 주제: 광범위한 산업의 시장 성장 전망, 기업의 재무 성과, 투자 및 자금 조...  \n",
      "4  핵심 주제: 글로벌 기업 경영 활동 및 시장 전망. 다양한 산업 분야에서 기업들의 ...  \n"
     ]
    }
   ],
   "source": [
    "def build_prompt(code_value: int, code_vector: str, ohlcv_summary: str):\n",
    "    prompt = (\n",
    "        \"### 코드북\\n\" + str(code_value) +\"\\n\\n\"\n",
    "        \"### 코드북 벡터\\n\" + str(code_vector) + \"\\n\\n\"\n",
    "        \"### OHLCV 시계열\\n\" + ohlcv_summary + \"\\n\\n\"\n",
    "\n",
    "        \"위의 Code 벡터 정보와 OHLCV 시계열을 바탕으로, 해당 구간의 시장 움직임을 설명할 수 있는 한국어 뉴스 요약을 2~3 문장으로 작성하라.\"\n",
    "        \"데이터에 기반한 보수적 설명만 사용하고, 입력에 없는 사건을 새로 만들어내지 마라.\"\n",
    "    )\n",
    "    return prompt\n",
    "    \n",
    "# 프롬프트 컬럼 생성 (레이블은 placeholder)\n",
    "df_all[\"prompt\"] = df_all.apply(\n",
    "    lambda row: build_prompt(\n",
    "        code_value=row[\"code\"],\n",
    "        code_vector=row[\"code_str\"],\n",
    "        ohlcv_summary=row[\"ohlcv_summary\"],\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# 실제 프로젝트에서는 아래 completion을 사람/teacher LLM으로 채워넣어야 함\n",
    "# silver label을 llm api로 사용하거나 사람 손으로 gole label을 붙여 넣어야 함\n",
    "df_all[\"completion\"] = df_all[\"text\"]\n",
    "\n",
    "print(\"[ALL with prompt/completion] head:\\n\",\n",
    "      df_all[[\"date\", \"code\", \"prompt\", \"completion\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "430a1620-36c7-49f2-a512-f81879bc5d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSONL to prepared_data/train.jsonl\n"
     ]
    }
   ],
   "source": [
    "# import boto3\n",
    "import json\n",
    "\n",
    "def export_jsonl(df: pd.DataFrame, out_path: str) -> None:\n",
    "    os.makedirs(os.path.dirname(out_path) or \".\", exist_ok=True)\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for row in df.itertuples():\n",
    "            rec = {\n",
    "                \"prompt\": getattr(row, \"prompt\"),\n",
    "                \"completion\": getattr(row, \"completion\"),\n",
    "                \"date\": str(getattr(row, \"date\")),\n",
    "            }\n",
    "            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"Saved JSONL to {out_path}\")\n",
    "\n",
    "export_jsonl(df_all, OUTPUT_JSONL_LOCAL_PATH)\n",
    "\n",
    "# upload to s3 bucket\n",
    "# s3 = boto3.client(\"s3\")\n",
    "# s3.upload_file(OUTPUT_JSONL_LOCAL_PATH, BUCKET, OUTPUT_JSONL_S3_KEY)\n",
    "\n",
    "# print(f\"Uploaded to s3://{BUCKET}/{OUTPUT_JSONL_S3_KEY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85807ccd-5394-4353-9659-806a4ec060f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LLM Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7fbc365-56ec-423c-9f2b-3631453b25bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    ")\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b409081-f5fd-4d2f-af89-e2c0563f0c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainConfig(model_name_or_path='meta-llama/Meta-Llama-3-8B-Instruct', train_jsonl='prepared_data/train.jsonl', output_dir='./model', max_length=200, per_device_train_batch_size=1, gradient_accumulation_steps=16, num_train_epochs=3, learning_rate=0.0002, warmup_ratio=0.03, logging_steps=50, save_steps=500, seed=42, dataloader_num_workers=2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class TrainConfig:\n",
    "    # 1) 모델 & 데이터\n",
    "    model_name_or_path: str = \"meta-llama/Meta-Llama-3-8B-Instruct\"  # 원하는 베이스 LLM 이름\n",
    "    train_jsonl: str = \"prepared_data/train.jsonl\"          # 학습시킬 json prompt\n",
    "    \n",
    "    # 결과 저장 위치: EBS 볼륨 내 현재 작업 디렉토리 기준 \"./model\"\n",
    "    output_dir: str = \"./model\"\n",
    "\n",
    "    # 2) 토크나이즈 & 길이\n",
    "    max_length: int = 200\n",
    "\n",
    "    # 3) 학습 하이퍼파라미터\n",
    "    per_device_train_batch_size: int = 1\n",
    "    gradient_accumulation_steps: int = 16\n",
    "    num_train_epochs: int = 3\n",
    "    learning_rate: float = 2e-4\n",
    "    warmup_ratio: float = 0.03\n",
    "\n",
    "    # 4) 로깅 & 저장\n",
    "    logging_steps: int = 50\n",
    "    save_steps: int = 500\n",
    "    seed: int = 42\n",
    "    # 5) 기타\n",
    "    dataloader_num_workers: int = 2  # Colab이면 0~2 정도로 유지\n",
    "\n",
    "    # device_map=\"auto\"\n",
    "    # load_in_4bit=True\n",
    "\n",
    "cfg = TrainConfig()\n",
    "cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f10ee7dc-91ab-4f24-8756-3cbca0472a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_jsonl_path(path: str) -> str:\n",
    "    \"\"\"\n",
    "    - s3://bucket/key 형식이면 /tmp/train.jsonl 로 다운로드 후 해당 경로 반환\n",
    "    - 그 외에는 로컬 경로 그대로 반환\n",
    "    \"\"\"\n",
    "    if path.startswith(\"s3://\"):\n",
    "        no_scheme = path[5:]\n",
    "        bucket, key = no_scheme.split(\"/\", 1)\n",
    "\n",
    "        local_path = \"/tmp/train.jsonl\"\n",
    "        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "\n",
    "        s3 = boto3.client(\"s3\")\n",
    "        s3.download_file(bucket, key, local_path)\n",
    "        print(f\"[INFO] downloaded {path} -> {local_path}\")\n",
    "        return local_path\n",
    "    else:\n",
    "        return path\n",
    "\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "seed_everything(cfg.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f480971-d2f5-46a9-b241-8a66372b24e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonlSftDataset(Dataset):\n",
    "    \"\"\"\n",
    "    SFT용 JSONL Dataset.\n",
    "    각 row는 {\"prompt\": \"...\", \"completion\": \"...\"} 형태여야 함.\n",
    "    반환되는 input_ids, attention_mask, labels는 모두 동일 길이를 보장해야 한다.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, jsonl_path, tokenizer, max_length=1024):\n",
    "        self.samples = []\n",
    "        with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                obj = json.loads(line)\n",
    "                self.samples.append(obj)\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.samples[idx]\n",
    "        prompt = \" \".join(str(item[\"prompt\"]).split())\n",
    "        completion = \" \".join(str(item[\"completion\"]).split())\n",
    "\n",
    "        # 1) 프롬프트 + completion 합치기\n",
    "        full_text = prompt + completion\n",
    "\n",
    "        # 2) tokenizer로 일괄 encoding (truncation=True)\n",
    "        enc = self.tokenizer(\n",
    "            full_text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            add_special_tokens=True,\n",
    "        )\n",
    "\n",
    "        input_ids = enc[\"input_ids\"]\n",
    "        attn_mask = enc[\"attention_mask\"]\n",
    "\n",
    "        # 3) prompt만 tokenize해서 길이 파악\n",
    "        prompt_ids = self.tokenizer(\n",
    "            prompt,\n",
    "            add_special_tokens=False,\n",
    "        )[\"input_ids\"]\n",
    "\n",
    "        # BOS 토큰 보정\n",
    "        bos_extra = 1 if (len(input_ids) > 0 and input_ids[0] == self.tokenizer.bos_token_id) else 0\n",
    "\n",
    "        prompt_len = len(prompt_ids) + bos_extra\n",
    "\n",
    "        # 4) labels = input_ids 복사\n",
    "        labels = input_ids.copy()\n",
    "\n",
    "        # prompt 구간 -100\n",
    "        for i in range(prompt_len):\n",
    "            if i < len(labels):\n",
    "                labels[i] = -100\n",
    "\n",
    "        # ※ 여기서 중요한 부분: \n",
    "        # input_ids, attention_mask, labels 모두 정확히 동일 길이\n",
    "        # collator가 나중에 batch padding 할 것이므로 Dataset에서는 길이를 맞추기만 하면 된다.\n",
    "\n",
    "        assert len(input_ids) == len(labels), f\"label mismatch: {len(input_ids)} vs {len(labels)}\"\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(attn_mask, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f2aa4e-dd63-4ab7-8cb9-63dea803b25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access OK!\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from huggingface_hub import HfApi\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "try:\n",
    "    hf_hub_download(\n",
    "        repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        filename=\"config.json\"\n",
    "    )\n",
    "    print(\"Access OK!\")\n",
    "except Exception as e:\n",
    "    print(\"Access error:\", e)\n",
    "\n",
    "import requests\n",
    "\n",
    "HF_TOKEN = \"hf_xxxxxxxxx\"   # 너의 것 넣기\n",
    "headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
    "\n",
    "url = \"https://huggingface.co/api/models/meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "res = requests.get(url, headers=headers)\n",
    "\n",
    "print(res.status_code)\n",
    "# print(res.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea081f03-d210-481b-bb6a-5b6a3e00f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 토크나이저\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    cfg.model_name_or_path,\n",
    "    use_fast=True,\n",
    ")\n",
    "\n",
    "# pad 토큰 세팅 (없는 모델들 대비)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "447d59de-8c8c-4cf6-a213-9c087739e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd3e5f7d27147669cda996a1bdec583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef1937df1cc4c1bb22e01d018bc67a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f202adced642a88eb737a24a55f6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c952b89963248a895374f6e9439b582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae4c8b4e00b4f32b3e09e50c2c4ecd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06e7545a6264ad1bef58f8ea7dfbf0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e0a731db8144c1bdb30a510003f652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46847386d4b949eaa9097240a7f7ada8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,815,744 || all params: 8,037,076,992 || trainable%: 0.0848\n"
     ]
    }
   ],
   "source": [
    "# 2) 모델 로드\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    cfg.model_name_or_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda\",  # GPU 있으면 GPU, 없으면 CPU\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False  # 학습 시에는 False 권장\n",
    "\n",
    "# 3) LoRA 설정\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    # LLaMA 계열 기준. 다른 모델이면 target_modules 이름만 바꿔주면 됨.\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cef9a257-0f71-4fbd-88db-687b0914e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# pad token이 없는 모델이면 eos를 pad로 재사용\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "def sft_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: list of {\"input_ids\": 1D tensor, \"attention_mask\": 1D tensor, \"labels\": 1D tensor}\n",
    "    를 받아서, padding된 배치를 반환.\n",
    "    \"\"\"\n",
    "\n",
    "    input_ids_list = [item[\"input_ids\"] for item in batch]\n",
    "    attention_mask_list = [item[\"attention_mask\"] for item in batch]\n",
    "    labels_list = [item[\"labels\"] for item in batch]\n",
    "\n",
    "    # 배치 안에서 가장 긴 길이에 맞춰 패딩\n",
    "    input_ids_padded = pad_sequence(\n",
    "        input_ids_list,\n",
    "        batch_first=True,\n",
    "        padding_value=tokenizer.pad_token_id,\n",
    "    )\n",
    "\n",
    "    attention_mask_padded = pad_sequence(\n",
    "        attention_mask_list,\n",
    "        batch_first=True,\n",
    "        padding_value=0,          # 패딩 위치는 0\n",
    "    )\n",
    "\n",
    "    labels_padded = pad_sequence(\n",
    "        labels_list,\n",
    "        batch_first=True,\n",
    "        padding_value=-100,       # loss에서 무시될 값\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids_padded,\n",
    "        \"attention_mask\": attention_mask_padded,\n",
    "        \"labels\": labels_padded,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d061871f-c33d-432c-83fa-3a6d6a766225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train JSONL local path: prepared_data/train.jsonl\n",
      "Total samples: 226, train: 204, val: 22\n"
     ]
    }
   ],
   "source": [
    "# S3 또는 로컬 경로를 실제 로컬 파일로 resolve\n",
    "train_jsonl_local = resolve_jsonl_path(cfg.train_jsonl)\n",
    "print(\"Train JSONL local path:\", train_jsonl_local)\n",
    "\n",
    "# Dataset 생성\n",
    "from torch.utils.data import Subset\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# 1) 전체 dataset 생성\n",
    "full_dataset = JsonlSftDataset(\n",
    "    jsonl_path=train_jsonl_local,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=cfg.max_length,\n",
    ")\n",
    "\n",
    "# 2) train / val split (예: 90% / 10%)\n",
    "n = len(full_dataset)\n",
    "val_ratio = 0.1\n",
    "val_size = max(1, int(n * val_ratio))\n",
    "\n",
    "indices = list(range(n))\n",
    "import random\n",
    "random.shuffle(indices)\n",
    "\n",
    "val_indices = indices[:val_size]\n",
    "train_indices = indices[val_size:]\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "eval_dataset = Subset(full_dataset, val_indices)\n",
    "\n",
    "print(f\"Total samples: {n}, train: {len(train_dataset)}, val: {len(eval_dataset)}\")\n",
    "\n",
    "# 3) collator (우리가 만든 labels를 그대로 유지)\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True,           # 배치 내 최장 길이에 맞춰 패딩\n",
    "    # max_length=cfg.max_length,  # (선택) 강제로 이 길이까지 패딩/컷팅하고 싶으면 설정\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79a9f42b-4df0-4e1f-af29-54b34a81c149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eddec589-9c25-42d1-9a4e-3ff9c5812d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer ready.\n"
     ]
    }
   ],
   "source": [
    "# trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "os.makedirs(cfg.output_dir, exist_ok=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=cfg.output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    num_train_epochs=cfg.num_train_epochs,\n",
    "    per_device_train_batch_size=cfg.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=cfg.gradient_accumulation_steps,\n",
    "    learning_rate=cfg.learning_rate,\n",
    "    warmup_ratio=cfg.warmup_ratio,\n",
    "\n",
    "    logging_steps=cfg.logging_steps,\n",
    "    save_steps=cfg.save_steps,\n",
    "    save_total_limit=3,\n",
    "\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "\n",
    "    seed=cfg.seed,\n",
    "    report_to=\"none\",\n",
    "    dataloader_num_workers=cfg.dataloader_num_workers,\n",
    "\n",
    "    # 추가: epoch마다 eval_loss 계산\n",
    "    eval_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,   # ← 추가\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"Trainer ready.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13712be7-a5ef-4c4c-8e65-ca54ae1b2fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(train_dataset)):\n",
    "    \n",
    "    sample = train_dataset[i]\n",
    "    print(len(sample[\"input_ids\"]), len(sample[\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa67837f-2a3b-4ec9-8b31-b84146ddc943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 02:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.699912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.151138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.119790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=39, training_loss=0.8509030464367989, metrics={'train_runtime': 139.1183, 'train_samples_per_second': 4.399, 'train_steps_per_second': 0.28, 'total_flos': 5516622161510400.0, 'train_loss': 0.8509030464367989, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75afe8c8-c6c2-472b-bbfd-8b09adaef10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def save_metrics_with_timestamp(df, prefix, out_dir=\"./logs\"):\n",
    "    # 1) 디렉토리 생성\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # 2) 타임스탬프 생성\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # 3) 파일 경로 생성\n",
    "    filename = f\"{prefix}_{ts}.csv\"\n",
    "    path = os.path.join(out_dir, filename)\n",
    "\n",
    "    # 4) CSV 저장\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"Saved metrics to: {path}\")\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f143950-d9ab-45e7-9a91-21ef54b8e70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metrics to: ./logs/lora_metrics_20251206_031304.csv\n",
      "   epoch  eval_loss  perplexity\n",
      "0    1.0   0.699912    2.013576\n",
      "1    2.0   0.151138    1.163157\n",
      "2    3.0   0.119790    1.127260\n"
     ]
    }
   ],
   "source": [
    "#epcoh별 eval_loss와 perplexity 정리\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "log_history = trainer.state.log_history\n",
    "\n",
    "rows = []\n",
    "for log in log_history:\n",
    "    # eval 단계 로그만 골라서 사용\n",
    "    if \"eval_loss\" in log:\n",
    "        epoch = log.get(\"epoch\", None)\n",
    "        eval_loss = log[\"eval_loss\"]\n",
    "        perplexity = math.exp(eval_loss)\n",
    "        rows.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"eval_loss\": eval_loss,\n",
    "            \"perplexity\": perplexity,\n",
    "        })\n",
    "\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "filename = \"lora_metrics\"\n",
    "save_metrics_with_timestamp(df_metrics, filename)\n",
    "print(df_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69687144-cb8d-45df-8199-c9264201da18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA fine-tuning 완료. 저장 위치: ./model\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(cfg.output_dir)      # LoRA 어댑터 포함한 모델 저장\n",
    "tokenizer.save_pretrained(cfg.output_dir)\n",
    "\n",
    "print(\"LoRA fine-tuning 완료. 저장 위치:\", cfg.output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c3e552-6016-4e0e-ae8c-f56bdf5876c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9f9859fdb9448b9dadf8270495219a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "당신은 미국 주식 애널리스트다.\n",
      "\n",
      "[종목 코드] NVDA\n",
      "[기간] 2025-12-05\n",
      "\n",
      "[OHLCV 요약]\n",
      "- 시가: 370.5398\n",
      "- 고가: 372.5257\n",
      "- 저가: 367.9274\n",
      "- 종가: 367.9755\n",
      "- 거래량: 7391068.0\n",
      "\n",
      "[VQ 코드 시퀀스]\n",
      "[0.021593764424324,\t0.1893500536680221,\t0.0058695869520306,\t0.0947726070880889,\t-9.261945399163935e-28,\t0.0349617674946785,\t0.4011827707290649,\t0.5699447393417358]\n",
      "\n",
      "[뉴스 헤드라인]\n",
      "- \"나스닥 종합지수는 화요일 1.3% 상승, 기술株 주도\"\n",
      "- \"오피스 소프트웨어 기업, 다양한 제품 출시 계획 발표\"\n",
      "- \"신기술 기업, 다양한 인수합병 및 투자 유치 발표\"\n",
      "\n",
      "핵심 주제: 2025년 초 다양한 산업의 혁신 및 성장 전망. 기업들은 다양한 제품 및 서비스 출시, 인수합병 및 투자 유치 등을 통해 기업 가치 및 성장 전망을 높이고 있습니다.\n",
      "\n",
      "핵심 주제 주제: 기업의 혁신 및 성장 전망, 시장 동향 및 기업 실적. 다양한 산업의 기업들이 다양한 제품 및 서비스 출시, 인수합병 및 투자 유치 등을 통해 기업 가치 및 성장 전망을 높이고 있습니다. 기업들의 혁신 및 성장 전망은 시장 동향 및 기업 실적과 직접적으로 연관이 있습니다.\n",
      "\n",
      "핵심 주제 주제: 기업의 혁신 및 성장 전망, 시장 동향 및 기업 실적. 다양한 산업의 기업들이 다양한 제품 및 서비스 출시, 인수합병 및 투자 유치 등을 통해 기업 가치 및 성장 전망을 높이고 있습니다. 기업들의 혁\n"
     ]
    }
   ],
   "source": [
    "#simple test\n",
    "from peft import PeftModel\n",
    "\n",
    "# 베이스 모델 다시 로드 (새 세션이거나, 검증용)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    cfg.model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\",\n",
    ")\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "base_model.config.use_cache = True  # inference에서는 True로 켜도 됩니다.\n",
    "\n",
    "lora_model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    cfg.output_dir,\n",
    ")\n",
    "lora_model.eval()\n",
    "\n",
    "def generate_comment(prompt_text: str, max_new_tokens: int = 256):\n",
    "    inputs = tokenizer(\n",
    "        prompt_text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=cfg.max_length,\n",
    "    ).to(lora_model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = lora_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=0.7,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "test_prompt = \"\"\"당신은 미국 주식 애널리스트다.\n",
    "\n",
    "[종목 코드] NVDA\n",
    "[기간] 2025-12-05\n",
    "\n",
    "[OHLCV 요약]\n",
    "- 시가: 370.5398\n",
    "- 고가: 372.5257\n",
    "- 저가: 367.9274\n",
    "- 종가: 367.9755\n",
    "- 거래량: 7391068.0\n",
    "\n",
    "[VQ 코드 시퀀스]\n",
    "[0.021593764424324,\t0.1893500536680221,\t0.0058695869520306,\t0.0947726070880889,\t-9.261945399163935e-28,\t0.0349617674946785,\t0.4011827707290649,\t0.5699447393417358]\n",
    "\n",
    "[뉴스 헤드라인]\n",
    "- \"나스닥 종합지수는 화요일 1.5% 이상 폭락한 후 수요일 1.2% 하락했습니다. S&P 500과 다우존스 산업평균지수는 모두 0.8% 하락했습니다.\"\n",
    "\n",
    "위 정보를 종합하여 300~400자 분량의 시황 코멘트를 작성하라.\n",
    "\n",
    "### 답변:\n",
    "\"\"\"\n",
    "comment = generate_comment(test_prompt)\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eac295-45fc-47c8-a0d3-bb2a49556383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e1d57-26a1-4a69-9b29-98a30d9e3b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4654b5b6-23b9-49df-916d-66e226fb4861",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a996c905-ab20-4944-8633-356cef5c6a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
